{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Prediction with LSTM\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    " dataX, dataY = [], []\n",
    " for i in range(len(dataset)-look_back-1):\n",
    "  a = dataset[i:(i+look_back), 0]\n",
    "  dataX.append(a)\n",
    "  dataY.append(dataset[i + look_back, 0])\n",
    " return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: \n",
      "             date dist        co       no2        o3  so2  ch4      hcho\n",
      "0     2018-04-30   q1  0.036519  0.000059  0.127509  0.0    0  0.000000\n",
      "1     2018-05-01   q1  0.035765  0.000053  0.128756  0.0    0  0.000000\n",
      "2     2018-05-02   q1  0.037218  0.000051  0.127053  0.0    0  0.000000\n",
      "3     2018-05-03   q1  0.000000  0.000000  0.120879  0.0    0  0.000000\n",
      "4     2018-05-04   q1  0.000000  0.000000  0.121712  0.0    0  0.000000\n",
      "...          ...  ...       ...       ...       ...  ...  ...       ...\n",
      "1194  2021-08-06   q1  0.000000  0.000000  0.120559  0.0    0  0.000000\n",
      "1195  2021-08-07   q1  0.020865  0.000000  0.119257  0.0    0  0.000000\n",
      "1196  2021-08-08   q1  0.025278  0.000000  0.118261  0.0    0  0.000000\n",
      "1197  2021-08-09   q1  0.000000  0.000000  0.120582  0.0    0  0.000295\n",
      "1198  2021-08-10   q1  0.026092  0.000000  0.120392  0.0    0  0.000000\n",
      "\n",
      "[1199 rows x 8 columns]\n",
      "Dataset: \n",
      " [[5.89875090e-05]\n",
      " [5.31632941e-05]\n",
      " [5.09173915e-05]\n",
      " ...\n",
      " [0.00000000e+00]\n",
      " [0.00000000e+00]\n",
      " [0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset_name = \"q1-20210810\"\n",
    "product_name = \"no2\"\n",
    "file_path = 'dataset/'+dataset_name+'.csv'\n",
    "dataframe = pd.read_csv(file_path)\n",
    "print(\"Dataframe: \\n\", dataframe)\n",
    "dataset = numpy.asarray(dataframe[product_name]).reshape(-1,1)\n",
    "print(\"Dataset: \\n\", dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after scale: \n",
      " [[0.30101245]\n",
      " [0.27129156]\n",
      " [0.25983075]\n",
      " ...\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "print(\"Dataset after scale: \\n\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.9)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainX shape:  (1077, 1)\n",
      "TrainY shape:  (1077,)\n"
     ]
    }
   ],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "print(\"TrainX shape: \", trainX.shape)\n",
    "print(\"TrainY shape: \", trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 4)                 96        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "108/108 - 3s - loss: 0.0399 - val_loss: 0.0155\n",
      "Epoch 2/1000\n",
      "108/108 - 0s - loss: 0.0374 - val_loss: 0.0163\n",
      "Epoch 3/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0164\n",
      "Epoch 4/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0165\n",
      "Epoch 5/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0164\n",
      "Epoch 6/1000\n",
      "108/108 - 1s - loss: 0.0373 - val_loss: 0.0160\n",
      "Epoch 7/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 8/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 9/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0171\n",
      "Epoch 10/1000\n",
      "108/108 - 1s - loss: 0.0373 - val_loss: 0.0164\n",
      "Epoch 11/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 12/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 13/1000\n",
      "108/108 - 1s - loss: 0.0373 - val_loss: 0.0171\n",
      "Epoch 14/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 15/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 16/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 17/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 18/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 19/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 20/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 21/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 22/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0167\n",
      "Epoch 23/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 24/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 25/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 26/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 27/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 28/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 29/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 30/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 31/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0157\n",
      "Epoch 32/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 33/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0172\n",
      "Epoch 34/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0166\n",
      "Epoch 35/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 36/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 37/1000\n",
      "108/108 - 1s - loss: 0.0373 - val_loss: 0.0168\n",
      "Epoch 38/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 39/1000\n",
      "108/108 - 1s - loss: 0.0373 - val_loss: 0.0166\n",
      "Epoch 40/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 41/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 42/1000\n",
      "108/108 - 0s - loss: 0.0374 - val_loss: 0.0164\n",
      "Epoch 43/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 44/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 45/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 46/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0167\n",
      "Epoch 47/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 48/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 49/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0157\n",
      "Epoch 50/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 51/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 52/1000\n",
      "108/108 - 1s - loss: 0.0373 - val_loss: 0.0167\n",
      "Epoch 53/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 54/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 55/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 56/1000\n",
      "108/108 - 1s - loss: 0.0373 - val_loss: 0.0163\n",
      "Epoch 57/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 58/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 59/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 60/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 61/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0161\n",
      "Epoch 62/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 63/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 64/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 65/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 66/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 67/1000\n",
      "108/108 - 0s - loss: 0.0374 - val_loss: 0.0159\n",
      "Epoch 68/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0172\n",
      "Epoch 69/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 70/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 71/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 72/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 73/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 74/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 75/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 76/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 77/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 78/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 79/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 80/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 81/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 82/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 83/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 84/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 85/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0171\n",
      "Epoch 86/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 87/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 88/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0172\n",
      "Epoch 89/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0163\n",
      "Epoch 90/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0173\n",
      "Epoch 91/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 92/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 93/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0162\n",
      "Epoch 94/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 95/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 96/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 97/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 98/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 99/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 100/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0162\n",
      "Epoch 101/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 102/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 103/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0157\n",
      "Epoch 104/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0162\n",
      "Epoch 105/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 106/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 107/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0157\n",
      "Epoch 108/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 109/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0171\n",
      "Epoch 110/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 111/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 112/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 113/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 114/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 115/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 116/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 117/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 118/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 119/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 120/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 121/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 122/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 123/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 124/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 125/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 126/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 127/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 128/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 129/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 130/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 131/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 132/1000\n",
      "108/108 - 0s - loss: 0.0371 - val_loss: 0.0155\n",
      "Epoch 133/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0164\n",
      "Epoch 134/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 135/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 136/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 137/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 138/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 139/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 140/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 141/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 142/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 143/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 144/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0158\n",
      "Epoch 145/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 146/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0173\n",
      "Epoch 147/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 148/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 149/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 150/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 151/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 152/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0170\n",
      "Epoch 153/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 154/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0168\n",
      "Epoch 155/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 156/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 157/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 158/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0165\n",
      "Epoch 159/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0169\n",
      "Epoch 160/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 161/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 162/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 163/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 164/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 165/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 166/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0172\n",
      "Epoch 167/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0171\n",
      "Epoch 168/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 169/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 170/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 171/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 172/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 173/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 174/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 175/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 176/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 177/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 178/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 179/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 180/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0168\n",
      "Epoch 181/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 182/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0171\n",
      "Epoch 183/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 184/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 185/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 186/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 187/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 188/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 189/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 190/1000\n",
      "108/108 - 1s - loss: 0.0373 - val_loss: 0.0166\n",
      "Epoch 191/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 192/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 193/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 194/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 195/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 196/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 197/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 198/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 199/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 200/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0157\n",
      "Epoch 201/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 202/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 203/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 204/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 205/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 206/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 207/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0159\n",
      "Epoch 208/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 209/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 210/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 211/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 212/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 213/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 214/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 215/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 216/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 217/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 218/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 219/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 220/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 221/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 222/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0157\n",
      "Epoch 223/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0167\n",
      "Epoch 224/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 225/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 226/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 227/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0165\n",
      "Epoch 228/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 229/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0157\n",
      "Epoch 230/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 231/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 232/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 233/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 234/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 235/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 236/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 237/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 238/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0164\n",
      "Epoch 239/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 240/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 241/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0175\n",
      "Epoch 242/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0156\n",
      "Epoch 243/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 244/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 245/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 246/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 247/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 248/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 249/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 250/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 251/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 252/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0174\n",
      "Epoch 253/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 254/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 255/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 256/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 257/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 258/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0162\n",
      "Epoch 259/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 260/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 261/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 262/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 263/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0157\n",
      "Epoch 264/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 265/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0159\n",
      "Epoch 266/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 267/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 268/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 269/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 270/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 271/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 272/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0171\n",
      "Epoch 273/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 274/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0172\n",
      "Epoch 275/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 276/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 277/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 278/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 279/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 280/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 281/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 282/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 283/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0165\n",
      "Epoch 284/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 285/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 286/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 287/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 288/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 289/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 290/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 291/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 292/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 293/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 294/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0161\n",
      "Epoch 295/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0157\n",
      "Epoch 296/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 297/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 298/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 299/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 300/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 301/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0173\n",
      "Epoch 302/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 303/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 304/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 305/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 306/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 307/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 308/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 309/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 310/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 311/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 312/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 313/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 314/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 315/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 316/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 317/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 318/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 319/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 320/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 321/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 322/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 323/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 324/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 325/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 326/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 327/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 328/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 329/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 330/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 331/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 332/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 333/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 334/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 335/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 336/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 337/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 338/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 339/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 340/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 341/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 342/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 343/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 344/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 345/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 346/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 347/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 348/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 349/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 350/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 351/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 352/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0164\n",
      "Epoch 353/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 354/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 355/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 356/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 357/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 358/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 359/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 360/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 361/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 362/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 363/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0164\n",
      "Epoch 364/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 365/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 366/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 367/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 368/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 369/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 370/1000\n",
      "108/108 - 0s - loss: 0.0371 - val_loss: 0.0157\n",
      "Epoch 371/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0173\n",
      "Epoch 372/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 373/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 374/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 375/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 376/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 377/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 378/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 379/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 380/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 381/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 382/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 383/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0172\n",
      "Epoch 384/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 385/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 386/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 387/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0155\n",
      "Epoch 388/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0160\n",
      "Epoch 389/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 390/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 391/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 392/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 393/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 394/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 395/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 396/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 397/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 398/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 399/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 400/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 401/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 402/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 403/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0164\n",
      "Epoch 404/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 405/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 406/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0164\n",
      "Epoch 407/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 408/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 409/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 410/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 411/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 412/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 413/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 414/1000\n",
      "108/108 - 0s - loss: 0.0371 - val_loss: 0.0161\n",
      "Epoch 415/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0167\n",
      "Epoch 416/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 417/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 418/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 419/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 420/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 421/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 422/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 423/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 424/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 425/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 426/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 427/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 428/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 429/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 430/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 431/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 432/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 433/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 434/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 435/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0171\n",
      "Epoch 436/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 437/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 438/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0165\n",
      "Epoch 439/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 440/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 441/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 442/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 443/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 444/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 445/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 446/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 447/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 448/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0173\n",
      "Epoch 449/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0173\n",
      "Epoch 450/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 451/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0161\n",
      "Epoch 452/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 453/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 454/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 455/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 456/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 457/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 458/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 459/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 460/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 461/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 462/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 463/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 464/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 465/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 466/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 467/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 468/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 469/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 470/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 471/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 472/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 473/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 474/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0164\n",
      "Epoch 475/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 476/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 477/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 478/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 479/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 480/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 481/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 482/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 483/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 484/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 485/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 486/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 487/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 488/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0160\n",
      "Epoch 489/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0163\n",
      "Epoch 490/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 491/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0171\n",
      "Epoch 492/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 493/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 494/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 495/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 496/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0166\n",
      "Epoch 497/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0163\n",
      "Epoch 498/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 499/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 500/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 501/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 502/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 503/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 504/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 505/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 506/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 507/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 508/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 509/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0156\n",
      "Epoch 510/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 511/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 512/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0171\n",
      "Epoch 513/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 514/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0162\n",
      "Epoch 515/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 516/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 517/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 518/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 519/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 520/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 521/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 522/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 523/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 524/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 525/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 526/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 527/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 528/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 529/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 530/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 531/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 532/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 533/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 534/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 535/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 536/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 537/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 538/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 539/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0172\n",
      "Epoch 540/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 541/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 542/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 543/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 544/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 545/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 546/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 547/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 548/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 549/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 550/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 551/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 552/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 553/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 554/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 555/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 556/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0160\n",
      "Epoch 557/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 558/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 559/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 560/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 561/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 562/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 563/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 564/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 565/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 566/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 567/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 568/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 569/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 570/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 571/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 572/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 573/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 574/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 575/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 576/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 577/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 578/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 579/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 580/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 581/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 582/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 583/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 584/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 585/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 586/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 587/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 588/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 589/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 590/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 591/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0163\n",
      "Epoch 592/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 593/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 594/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 595/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 596/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 597/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 598/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 599/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 600/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 601/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 602/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 603/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 604/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 605/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 606/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 607/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 608/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 609/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0163\n",
      "Epoch 610/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 611/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 612/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 613/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 614/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 615/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 616/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 617/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 618/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 619/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 620/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 621/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 622/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 623/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 624/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 625/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 626/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 627/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 628/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 629/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 630/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 631/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0157\n",
      "Epoch 632/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 633/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 634/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 635/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 636/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 637/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 638/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 639/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0165\n",
      "Epoch 640/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 641/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 642/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 643/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 644/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 645/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 646/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 647/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 648/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 649/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 650/1000\n",
      "108/108 - 0s - loss: 0.0371 - val_loss: 0.0157\n",
      "Epoch 651/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 652/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 653/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 654/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 655/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 656/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 657/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 658/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 659/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 660/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 661/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 662/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 663/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 664/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 665/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0172\n",
      "Epoch 666/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 667/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 668/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 669/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0171\n",
      "Epoch 670/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 671/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 672/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 673/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 674/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 675/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 676/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 677/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 678/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 679/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 680/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 681/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 682/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0157\n",
      "Epoch 683/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 684/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 685/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 686/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 687/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 688/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 689/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 690/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 691/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 692/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 693/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 694/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 695/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 696/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 697/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 698/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 699/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 700/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 701/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 702/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 703/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 704/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 705/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 706/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 707/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 708/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 709/1000\n",
      "108/108 - 0s - loss: 0.0371 - val_loss: 0.0161\n",
      "Epoch 710/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 711/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 712/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 713/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 714/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 715/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0163\n",
      "Epoch 716/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 717/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 718/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 719/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 720/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 721/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 722/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 723/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 724/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 725/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 726/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 727/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 728/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 729/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 730/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 731/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 732/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0168\n",
      "Epoch 733/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 734/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 735/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 736/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 737/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 738/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 739/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 740/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 741/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 742/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0172\n",
      "Epoch 743/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 744/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 745/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 746/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 747/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0165\n",
      "Epoch 748/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 749/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 750/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 751/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 752/1000\n",
      "108/108 - 0s - loss: 0.0371 - val_loss: 0.0173\n",
      "Epoch 753/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 754/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 755/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 756/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 757/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 758/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 759/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 760/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 761/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 762/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 763/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 764/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 765/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 766/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 767/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 768/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 769/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 770/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 771/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 772/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 773/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 774/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 775/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 776/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 777/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 778/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 779/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0167\n",
      "Epoch 780/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0172\n",
      "Epoch 781/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 782/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 783/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 784/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 785/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 786/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 787/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0162\n",
      "Epoch 788/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 789/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 790/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 791/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 792/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 793/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 794/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 795/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 796/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 797/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 798/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 799/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 800/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 801/1000\n",
      "108/108 - 0s - loss: 0.0371 - val_loss: 0.0169\n",
      "Epoch 802/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 803/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 804/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 805/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 806/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 807/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 808/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 809/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 810/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 811/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 812/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 813/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 814/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 815/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 816/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 817/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 818/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 819/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 820/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 821/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 822/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 823/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 824/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 825/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 826/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 827/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 828/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0171\n",
      "Epoch 829/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 830/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 831/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 832/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 833/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 834/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 835/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 836/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 837/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 838/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 839/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 840/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 841/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 842/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 843/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 844/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 845/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 846/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 847/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 848/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 849/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 850/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 851/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 852/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 853/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 854/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 855/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 856/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0160\n",
      "Epoch 857/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 858/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 859/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 860/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 861/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 862/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 863/1000\n",
      "108/108 - 0s - loss: 0.0371 - val_loss: 0.0161\n",
      "Epoch 864/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 865/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 866/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 867/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 868/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 869/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 870/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 871/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 872/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 873/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 874/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 875/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 876/1000\n",
      "108/108 - 0s - loss: 0.0371 - val_loss: 0.0167\n",
      "Epoch 877/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 878/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 879/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 880/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 881/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 882/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 883/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 884/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 885/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 886/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0160\n",
      "Epoch 887/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 888/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 889/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 890/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 891/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 892/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 893/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 894/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 895/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 896/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 897/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 898/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 899/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 900/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 901/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 902/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 903/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 904/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0171\n",
      "Epoch 905/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 906/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 907/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 908/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 909/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 910/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 911/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 912/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 913/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 914/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 915/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 916/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 917/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 918/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 919/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 920/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 921/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 922/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 923/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 924/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 925/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 926/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 927/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 928/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 929/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 930/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 931/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 932/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 933/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 934/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 935/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 936/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 937/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 938/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 939/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 940/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 941/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 942/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 943/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 944/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 945/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0176\n",
      "Epoch 946/1000\n",
      "108/108 - 0s - loss: 0.0371 - val_loss: 0.0162\n",
      "Epoch 947/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0167\n",
      "Epoch 948/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 949/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 950/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 951/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 952/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 953/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 954/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 955/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 956/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 957/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 958/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 959/1000\n",
      "108/108 - 0s - loss: 0.0373 - val_loss: 0.0162\n",
      "Epoch 960/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 961/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 962/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 963/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 964/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0168\n",
      "Epoch 965/1000\n",
      "108/108 - 1s - loss: 0.0373 - val_loss: 0.0165\n",
      "Epoch 966/1000\n",
      "108/108 - 1s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 967/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 968/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 969/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0172\n",
      "Epoch 970/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 971/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 972/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 973/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 974/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 975/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 976/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 977/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 978/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 979/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 980/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 981/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 982/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 983/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 984/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 985/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0166\n",
      "Epoch 986/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 987/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 988/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0169\n",
      "Epoch 989/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0160\n",
      "Epoch 990/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 991/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 992/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 993/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0163\n",
      "Epoch 994/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 995/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0164\n",
      "Epoch 996/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0162\n",
      "Epoch 997/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 998/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 999/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 1000/1000\n",
      "108/108 - 0s - loss: 0.0372 - val_loss: 0.0161\n",
      "score: test score =  0.01608717255294323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/rnn-lstm-no2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/rnn-lstm-no2/assets\n"
     ]
    }
   ],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "history = model.fit(trainX, trainY, epochs=1000, batch_size=10, verbose=2,\n",
    "          validation_data=(testX, testY))\n",
    "\n",
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print('score: test score = ', score)\n",
    "\n",
    "# save the model\n",
    "model.save('models/rnn-lstm-'+product_name)\n",
    "# save the scaler\n",
    "dump(scaler, open('models/rnn-lstm-'+product_name+'/scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe3ff0511f0>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[15.30895878]]\n",
      "\n",
      " [[ 1.53089588]]]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "_input2d = numpy.array([[0.003],[0.0003]])\n",
    "_input_scaled2d = scaler.transform(_input2d)\n",
    "_input_scaled3d = _input_scaled2d[:, :, numpy.newaxis]\n",
    "print(_input_scaled3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_Y = testY[0][len(testY[0])-31:len(testY[0])-1]\n",
    "test_Ypred = testPredict[len(testPredict)-31:len(testPredict)-1]\n",
    "plt.subplots(figsize=(10, 5))\n",
    "plt.title(product_name.upper() + \" - Forecast vs Actual\", fontsize=14)\n",
    "plt.plot(pd.Series(numpy.ravel(test_Y)), \"bs-\", markersize=3, label=\"Actual\")\n",
    "plt.plot(pd.Series(numpy.ravel(test_Ypred)), \"ro-\", markersize=3, label=\"Forecast\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylim([-0.003,0.003])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00003776 RMSE max in Train = 0.00019596368656493723 , min = 0.0 , mean = 1.9956440678238014e-05\n",
      "Test Score: 0.00002486 RMSE max in Test = 0.0001271183864446357 , min = 0.0 , mean = 8.054272904577743e-06\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.8f RMSE' % (trainScore),\"max in Train =\", trainY.max(),\", min =\", trainY.min(),\", mean =\", trainY.mean())\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.8f RMSE' % (testScore),\"max in Test =\", testY.max(),\", min =\", testY.min(),\", mean =\", testY.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot baseline and predictions\n",
    "# #plt.plot(scaler.inverse_transform(testY),\"b-\", label=\"Train\")\n",
    "# plt.plot(trainPredictPlot,\"y-\", label=\"Train pred\")\n",
    "# #plt.plot(scaler.inverse_transform(testY)[0],\"b-\", label=\"Test\")\n",
    "# plt.plot(testPredictPlot, \"g-\", label=\"Test pred\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# #plt.ylim([-400,400])\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18f9e42b91da9395310def41b953de3eaf324ff700d0d0be600380b7bf53ba90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
