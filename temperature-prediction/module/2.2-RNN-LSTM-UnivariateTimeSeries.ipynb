{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Develop LSTM Models For Univariate Time Series Forecasting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "\n",
    "# univariate lstm example\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# preparing independent and dependent features\n",
    "def prepare_data(timeseries_data, n_features):\n",
    "\tX, y =[],[]\n",
    "\tfor i in range(len(timeseries_data)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_features\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(timeseries_data)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "dataset_name = \"q1\"\n",
    "product_name = \"no2\"\n",
    "file_path = 'dataset/'+dataset_name+'.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "print(data.tail(8))\n",
    "\n",
    "tmp = np.array(data[product_name])\n",
    "\n",
    "# Normalization: Chuan hoa du lieu => [0,1]\n",
    "print('===> Min max scaling')\n",
    "from sklearn import preprocessing as pp\n",
    "mms = pp.MinMaxScaler()\n",
    "data_mms = mms.fit_transform(tmp.reshape(-1,1))\n",
    "print(\"===> mms\\n\", data_mms, \"\\nmin: \",data_mms.min(),\"\\nmean: \",data_mms.mean(),\"\\nmax: \",data_mms.max(),)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            date dist        co  no2        o3       so2  ch4      hcho\n",
      "1191  2021-08-03   q1  0.027522  0.0  0.122755  0.000513    0  0.000257\n",
      "1192  2021-08-04   q1  0.025587  0.0  0.124452  0.000000    0  0.000000\n",
      "1193  2021-08-05   q1  0.028541  0.0  0.124218  0.000000    0  0.000000\n",
      "1194  2021-08-06   q1  0.000000  0.0  0.120559  0.000000    0  0.000000\n",
      "1195  2021-08-07   q1  0.020865  0.0  0.119257  0.000000    0  0.000000\n",
      "1196  2021-08-08   q1  0.025278  0.0  0.118261  0.000000    0  0.000000\n",
      "1197  2021-08-09   q1  0.000000  0.0  0.120582  0.000000    0  0.000295\n",
      "1198  2021-08-10   q1  0.026092  0.0  0.120392  0.000000    0  0.000000\n",
      "===> Min max scaling\n",
      "===> mms\n",
      " [[0.30101245]\n",
      " [0.27129156]\n",
      " [0.25983075]\n",
      " ...\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]] \n",
      "min:  0.0 \n",
      "mean:  0.09577134086237415 \n",
      "max:  1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# define input sequence\n",
    "#timeseries_data = [110, 125, 133, 146, 158, 172, 187, 196, 210]\n",
    "timeseries_data = data_mms\n",
    "print(timeseries_data)\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "X, y = prepare_data(timeseries_data, n_steps)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.30101245]\n",
      " [0.27129156]\n",
      " [0.25983075]\n",
      " ...\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "print(X),print(y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[0.30101245]\n",
      "  [0.27129156]\n",
      "  [0.25983075]]\n",
      "\n",
      " [[0.27129156]\n",
      "  [0.25983075]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.25983075]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]]\n",
      "[[0.        ]\n",
      " [0.        ]\n",
      " [0.47224881]\n",
      " ...\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "X.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1196, 3, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building LSTM Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=300, verbose=1)\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/300\n",
      "38/38 [==============================] - 2s 4ms/step - loss: 0.0385\n",
      "Epoch 2/300\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0360\n",
      "Epoch 3/300\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0358\n",
      "Epoch 4/300\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0357\n",
      "Epoch 5/300\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0356\n",
      "Epoch 6/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0356\n",
      "Epoch 7/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0354\n",
      "Epoch 8/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0355\n",
      "Epoch 9/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0353\n",
      "Epoch 10/300\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0355\n",
      "Epoch 11/300\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0354\n",
      "Epoch 12/300\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0353\n",
      "Epoch 13/300\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0352\n",
      "Epoch 14/300\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0352\n",
      "Epoch 15/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0352\n",
      "Epoch 16/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0351\n",
      "Epoch 17/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0351\n",
      "Epoch 18/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0351\n",
      "Epoch 19/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0349\n",
      "Epoch 20/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0349\n",
      "Epoch 21/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0351\n",
      "Epoch 22/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0349\n",
      "Epoch 23/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0349\n",
      "Epoch 24/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0348\n",
      "Epoch 25/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0348\n",
      "Epoch 26/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0347\n",
      "Epoch 27/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0347\n",
      "Epoch 28/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0347\n",
      "Epoch 29/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0346\n",
      "Epoch 30/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0347\n",
      "Epoch 31/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0346\n",
      "Epoch 32/300\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0348\n",
      "Epoch 33/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0347\n",
      "Epoch 34/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0347\n",
      "Epoch 35/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0346\n",
      "Epoch 36/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0348\n",
      "Epoch 37/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0346\n",
      "Epoch 38/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0348\n",
      "Epoch 39/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0348\n",
      "Epoch 40/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0346\n",
      "Epoch 41/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0347\n",
      "Epoch 42/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0346\n",
      "Epoch 43/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0346\n",
      "Epoch 44/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0346\n",
      "Epoch 45/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0345\n",
      "Epoch 46/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0347\n",
      "Epoch 47/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0346\n",
      "Epoch 48/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0347\n",
      "Epoch 49/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0347\n",
      "Epoch 50/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0345\n",
      "Epoch 51/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0345\n",
      "Epoch 52/300\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0347\n",
      "Epoch 53/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0345\n",
      "Epoch 54/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0345\n",
      "Epoch 55/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0346\n",
      "Epoch 56/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0347\n",
      "Epoch 57/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0345\n",
      "Epoch 58/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0345\n",
      "Epoch 59/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0345\n",
      "Epoch 60/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0345\n",
      "Epoch 61/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0345\n",
      "Epoch 62/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0345\n",
      "Epoch 63/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0345\n",
      "Epoch 64/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0345\n",
      "Epoch 65/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0345\n",
      "Epoch 66/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0345\n",
      "Epoch 67/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0345\n",
      "Epoch 68/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0345\n",
      "Epoch 69/300\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0345\n",
      "Epoch 70/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0345\n",
      "Epoch 71/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0345\n",
      "Epoch 72/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0345\n",
      "Epoch 73/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0344\n",
      "Epoch 74/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0344\n",
      "Epoch 75/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0346\n",
      "Epoch 76/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0346\n",
      "Epoch 77/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0346\n",
      "Epoch 78/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0344\n",
      "Epoch 79/300\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0345\n",
      "Epoch 80/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0344\n",
      "Epoch 81/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0344\n",
      "Epoch 82/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0344\n",
      "Epoch 83/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0344\n",
      "Epoch 84/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0345\n",
      "Epoch 85/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0344\n",
      "Epoch 86/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0345\n",
      "Epoch 87/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0344\n",
      "Epoch 88/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0345\n",
      "Epoch 89/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0345\n",
      "Epoch 90/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0344\n",
      "Epoch 91/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0344\n",
      "Epoch 92/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0344\n",
      "Epoch 93/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0344\n",
      "Epoch 94/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0344\n",
      "Epoch 95/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0344\n",
      "Epoch 96/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0344\n",
      "Epoch 97/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0344\n",
      "Epoch 98/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0343\n",
      "Epoch 99/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0344\n",
      "Epoch 100/300\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0344\n",
      "Epoch 101/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0344\n",
      "Epoch 102/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0344\n",
      "Epoch 103/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0345\n",
      "Epoch 104/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0344\n",
      "Epoch 105/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0343\n",
      "Epoch 106/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0343\n",
      "Epoch 107/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0344\n",
      "Epoch 108/300\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0343\n",
      "Epoch 109/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0342\n",
      "Epoch 110/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0343\n",
      "Epoch 111/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0344\n",
      "Epoch 112/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0343\n",
      "Epoch 113/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0343\n",
      "Epoch 114/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0343\n",
      "Epoch 115/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0343\n",
      "Epoch 116/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0343\n",
      "Epoch 117/300\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0343\n",
      "Epoch 118/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342\n",
      "Epoch 119/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0343\n",
      "Epoch 120/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0343\n",
      "Epoch 121/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0344\n",
      "Epoch 122/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0344\n",
      "Epoch 123/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0343\n",
      "Epoch 124/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342\n",
      "Epoch 125/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0344\n",
      "Epoch 126/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342\n",
      "Epoch 127/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0342\n",
      "Epoch 128/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0343\n",
      "Epoch 129/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0342\n",
      "Epoch 130/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0343\n",
      "Epoch 131/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0342\n",
      "Epoch 132/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0343\n",
      "Epoch 133/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0342\n",
      "Epoch 134/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0341\n",
      "Epoch 135/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342\n",
      "Epoch 136/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0342\n",
      "Epoch 137/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0341\n",
      "Epoch 138/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342\n",
      "Epoch 139/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0342\n",
      "Epoch 140/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0342\n",
      "Epoch 141/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0343\n",
      "Epoch 142/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0342\n",
      "Epoch 143/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0343\n",
      "Epoch 144/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0343\n",
      "Epoch 145/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342\n",
      "Epoch 146/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0344\n",
      "Epoch 147/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0343\n",
      "Epoch 148/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342\n",
      "Epoch 149/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342\n",
      "Epoch 150/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342\n",
      "Epoch 151/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342\n",
      "Epoch 152/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0343\n",
      "Epoch 153/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0341\n",
      "Epoch 154/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0342\n",
      "Epoch 155/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0342\n",
      "Epoch 156/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0341\n",
      "Epoch 157/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0341\n",
      "Epoch 158/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0343\n",
      "Epoch 159/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0342\n",
      "Epoch 160/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0341\n",
      "Epoch 161/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342\n",
      "Epoch 162/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0342\n",
      "Epoch 163/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0341\n",
      "Epoch 164/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0342\n",
      "Epoch 165/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0342\n",
      "Epoch 166/300\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0341\n",
      "Epoch 167/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0344\n",
      "Epoch 168/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0343\n",
      "Epoch 169/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0342\n",
      "Epoch 170/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0341\n",
      "Epoch 171/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342\n",
      "Epoch 172/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0341\n",
      "Epoch 173/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0341\n",
      "Epoch 174/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0341\n",
      "Epoch 175/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0341\n",
      "Epoch 176/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 177/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0343\n",
      "Epoch 178/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0341\n",
      "Epoch 179/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0341\n",
      "Epoch 180/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0341\n",
      "Epoch 181/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340\n",
      "Epoch 182/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 183/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0341\n",
      "Epoch 184/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0340\n",
      "Epoch 185/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0342\n",
      "Epoch 186/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0342\n",
      "Epoch 187/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0341\n",
      "Epoch 188/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0341\n",
      "Epoch 189/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0341\n",
      "Epoch 190/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0341\n",
      "Epoch 191/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0341\n",
      "Epoch 192/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0341\n",
      "Epoch 193/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0341\n",
      "Epoch 194/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0340\n",
      "Epoch 195/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340\n",
      "Epoch 196/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340\n",
      "Epoch 197/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340\n",
      "Epoch 198/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0341\n",
      "Epoch 199/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 200/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 201/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0342\n",
      "Epoch 202/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0340\n",
      "Epoch 203/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340\n",
      "Epoch 204/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 205/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0341\n",
      "Epoch 206/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0341\n",
      "Epoch 207/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 208/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0341\n",
      "Epoch 209/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 210/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340\n",
      "Epoch 211/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 212/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340\n",
      "Epoch 213/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0339\n",
      "Epoch 214/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 215/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340\n",
      "Epoch 216/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 217/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0339\n",
      "Epoch 218/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 219/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0339\n",
      "Epoch 220/300\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0340\n",
      "Epoch 221/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0341\n",
      "Epoch 222/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0340\n",
      "Epoch 223/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0339\n",
      "Epoch 224/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0340\n",
      "Epoch 225/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 226/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0340\n",
      "Epoch 227/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0341\n",
      "Epoch 228/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0340\n",
      "Epoch 229/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0341\n",
      "Epoch 230/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0339\n",
      "Epoch 231/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0339\n",
      "Epoch 232/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0340\n",
      "Epoch 233/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 234/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 235/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0341\n",
      "Epoch 236/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0339\n",
      "Epoch 237/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340\n",
      "Epoch 238/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 239/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0339\n",
      "Epoch 240/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 241/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0339\n",
      "Epoch 242/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0339\n",
      "Epoch 243/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0339\n",
      "Epoch 244/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340\n",
      "Epoch 245/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0342\n",
      "Epoch 246/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0339\n",
      "Epoch 247/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0338\n",
      "Epoch 248/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0340\n",
      "Epoch 249/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0339\n",
      "Epoch 250/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 251/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0339\n",
      "Epoch 252/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 253/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340\n",
      "Epoch 254/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0339\n",
      "Epoch 255/300\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0339\n",
      "Epoch 256/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0341\n",
      "Epoch 257/300\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0339\n",
      "Epoch 258/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340\n",
      "Epoch 259/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0339\n",
      "Epoch 260/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 261/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0338\n",
      "Epoch 262/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 263/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0339\n",
      "Epoch 264/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340\n",
      "Epoch 265/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0339\n",
      "Epoch 266/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0340\n",
      "Epoch 267/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0340\n",
      "Epoch 268/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0339\n",
      "Epoch 269/300\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0338\n",
      "Epoch 270/300\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0338\n",
      "Epoch 271/300\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0339\n",
      "Epoch 272/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0340\n",
      "Epoch 273/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0339\n",
      "Epoch 274/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0338\n",
      "Epoch 275/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0338\n",
      "Epoch 276/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0340\n",
      "Epoch 277/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0339\n",
      "Epoch 278/300\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0339\n",
      "Epoch 279/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0339\n",
      "Epoch 280/300\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0338\n",
      "Epoch 281/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0338\n",
      "Epoch 282/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0341\n",
      "Epoch 283/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0337\n",
      "Epoch 284/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0339\n",
      "Epoch 285/300\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0340\n",
      "Epoch 286/300\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0339\n",
      "Epoch 287/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0341\n",
      "Epoch 288/300\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0339\n",
      "Epoch 289/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0338\n",
      "Epoch 290/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0338\n",
      "Epoch 291/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0340\n",
      "Epoch 292/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0338\n",
      "Epoch 293/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0340\n",
      "Epoch 294/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0340\n",
      "Epoch 295/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0339\n",
      "Epoch 296/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0338\n",
      "Epoch 297/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0339\n",
      "Epoch 298/300\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0338\n",
      "Epoch 299/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0339\n",
      "Epoch 300/300\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0339\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff866bf4ac0>"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predicting For the next 10 data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# demonstrate prediction for next 10 days\n",
    "x_input = np.array([0.0, 0.0, 0.0])\n",
    "temp_input=list(x_input)\n",
    "lst_output=[]\n",
    "i=0\n",
    "while(i<10):\n",
    "    \n",
    "    if(len(temp_input)>3):\n",
    "        x_input=np.array(temp_input[1:])\n",
    "        print(\"{} day input {}\".format(i,x_input))\n",
    "        #print(x_input)\n",
    "        x_input = x_input.reshape((1, n_steps, n_features))\n",
    "        #print(x_input)\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(\"{} day output {}\".format(i,yhat))\n",
    "        temp_input.append(yhat[0][0])\n",
    "        temp_input=temp_input[1:]\n",
    "        #print(temp_input)\n",
    "        lst_output.append(yhat[0][0])\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_input = x_input.reshape((1, n_steps, n_features))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(yhat[0])\n",
    "        temp_input.append(yhat[0][0])\n",
    "        lst_output.append(yhat[0][0])\n",
    "        i=i+1\n",
    "    \n",
    "\n",
    "print(lst_output)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.06660733]\n",
      "1 day input [0.         0.         0.06660733]\n",
      "1 day output [[0.06761594]]\n",
      "2 day input [0.         0.06660733 0.06761594]\n",
      "2 day output [[0.06764034]]\n",
      "3 day input [0.06660733 0.06761594 0.06764034]\n",
      "3 day output [[0.07240346]]\n",
      "4 day input [0.06761594 0.06764034 0.07240346]\n",
      "4 day output [[0.07258154]]\n",
      "5 day input [0.06764034 0.07240346 0.07258154]\n",
      "5 day output [[0.07258689]]\n",
      "6 day input [0.07240346 0.07258154 0.07258689]\n",
      "6 day output [[0.07306876]]\n",
      "7 day input [0.07258154 0.07258689 0.07306876]\n",
      "7 day output [[0.07309476]]\n",
      "8 day input [0.07258689 0.07306876 0.07309476]\n",
      "8 day output [[0.07309555]]\n",
      "9 day input [0.07306876 0.07309476 0.07309555]\n",
      "9 day output [[0.07314467]]\n",
      "[0.066607326, 0.06761594, 0.06764034, 0.07240346, 0.07258154, 0.07258689, 0.07306876, 0.073094755, 0.073095545, 0.073144674]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "timeseries_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.30101245],\n",
       "       [0.27129156],\n",
       "       [0.25983075],\n",
       "       ...,\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "len(timeseries_data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1199"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "lst_output"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-828.3983,\n",
       " -320.70245,\n",
       " -214.61783,\n",
       " -19.016754,\n",
       " -6.2733407,\n",
       " -0.1732224,\n",
       " 0.28148425,\n",
       " 0.1405233,\n",
       " 0.099877134,\n",
       " 0.11149557]"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "lst_output"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.066607326,\n",
       " 0.06761594,\n",
       " 0.06764034,\n",
       " 0.07240346,\n",
       " 0.07258154,\n",
       " 0.07258689,\n",
       " 0.07306876,\n",
       " 0.073094755,\n",
       " 0.073095545,\n",
       " 0.073144674]"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizaing The Output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "day_new=np.arange(1,1200)\n",
    "day_pred=np.arange(1200,1210)\n",
    "print(len(day_new), len(day_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1199 10\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "#plt.plot(day_new,timeseries_data, \"bs-\", markersize=5, label=\"Actual\")\n",
    "plt.plot(day_pred,lst_output, \"ro-\", markersize=5, label=\"Forecast\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylim([-0.1,0.1])\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "7b2db577e2e3c3d59c019c7bce89b93331fb3ae1c9a593654a8d90dfac1c6c30"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}