{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Prediction with LSTM\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    " dataX, dataY = [], []\n",
    " for i in range(len(dataset)-look_back-1):\n",
    "  a = dataset[i:(i+look_back), 0]\n",
    "  dataX.append(a)\n",
    "  dataY.append(dataset[i + look_back, 0])\n",
    " return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: \n",
      "             date dist        co       no2        o3  so2  ch4      hcho\n",
      "0     2018-04-30   q1  0.036519  0.000059  0.127509  0.0    0  0.000000\n",
      "1     2018-05-01   q1  0.035765  0.000053  0.128756  0.0    0  0.000000\n",
      "2     2018-05-02   q1  0.037218  0.000051  0.127053  0.0    0  0.000000\n",
      "3     2018-05-03   q1  0.000000  0.000000  0.120879  0.0    0  0.000000\n",
      "4     2018-05-04   q1  0.000000  0.000000  0.121712  0.0    0  0.000000\n",
      "...          ...  ...       ...       ...       ...  ...  ...       ...\n",
      "1281  2021-11-01   q1  0.032100  0.000000  0.120907  0.0    0  0.000000\n",
      "1282  2021-11-02   q1  0.000000  0.000239  0.115687  0.0    0  0.000239\n",
      "1283  2021-11-03   q1  0.030268  0.000000  0.115781  0.0    0  0.000000\n",
      "1284  2021-11-04   q1  0.028053  0.000200  0.116181  0.0    0  0.000200\n",
      "1285  2021-11-05   q1  0.000000  0.000000  0.111895  0.0    0  0.000000\n",
      "\n",
      "[1286 rows x 8 columns]\n",
      "Dataset: \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"q1\"\n",
    "product_name = \"so2\"\n",
    "file_path = 'dataset/'+dataset_name+'.csv'\n",
    "dataframe = pd.read_csv(file_path)\n",
    "print(\"Dataframe: \\n\", dataframe)\n",
    "dataset = numpy.asarray(dataframe[product_name]).reshape(-1,1)\n",
    "print(\"Dataset: \\n\", dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after scale: \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "print(\"Dataset after scale: \\n\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.9)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainX shape:  (1155, 1)\n",
      "TrainY shape:  (1155,)\n"
     ]
    }
   ],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "print(\"TrainX shape: \", trainX.shape)\n",
    "print(\"TrainY shape: \", trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 4)                 96        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "116/116 - 6s - loss: 0.0124 - val_loss: 0.0068\n",
      "Epoch 2/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 3/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0071\n",
      "Epoch 4/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 5/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 6/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 7/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 8/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 9/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 10/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 11/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 12/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 13/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 14/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 15/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 16/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 17/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 18/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 19/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 20/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 21/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 22/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 23/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 24/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 25/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 26/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 27/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 28/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 29/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 30/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 31/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 32/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 33/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 34/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 35/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 36/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 37/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 38/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 39/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 40/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 41/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 42/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 43/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 44/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 45/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 46/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 47/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 48/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 49/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 50/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 51/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 52/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 53/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 54/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 55/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 56/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 57/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 58/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 59/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 60/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 61/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 62/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 63/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 64/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 65/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 66/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 67/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 68/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 69/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 70/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 71/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 72/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 73/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 74/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 75/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 76/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 77/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 78/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 79/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 80/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 81/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 82/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 83/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 84/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 85/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 86/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 87/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 88/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 89/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 90/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 91/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 92/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 93/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 94/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 95/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 96/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 97/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 98/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 99/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 100/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 101/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 102/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 103/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 104/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 105/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0071\n",
      "Epoch 106/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 107/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 108/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 109/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 110/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 111/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 112/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 113/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 114/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 115/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 116/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 117/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 118/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 119/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 120/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 121/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 122/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 123/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 124/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 125/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 126/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 127/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0072\n",
      "Epoch 128/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 129/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 130/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 131/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 132/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 133/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 134/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 135/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 136/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 137/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 138/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 139/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 140/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 141/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 142/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 143/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 144/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 145/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 146/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 147/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 148/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 149/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 150/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 151/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 152/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 153/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 154/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 155/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 156/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 157/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 158/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 159/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 160/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 161/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 162/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 163/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 164/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 165/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 166/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 167/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 168/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 169/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 170/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 171/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 172/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 173/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 174/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 175/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 176/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 177/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 178/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 179/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 180/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 181/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 182/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 183/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 184/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 185/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 186/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 187/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 188/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 189/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 190/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 191/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 192/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 193/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 194/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 195/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 196/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 197/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 198/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 199/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 200/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 201/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 202/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 203/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 204/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 205/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 206/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 207/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 208/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 209/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 210/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 211/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 212/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 213/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 214/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 215/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 216/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 217/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 218/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 219/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 220/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 221/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 222/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 223/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 224/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 225/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 226/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 227/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 228/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 229/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 230/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 231/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 232/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 233/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 234/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 235/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 236/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 237/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 238/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 239/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 240/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 241/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 242/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 243/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 244/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 245/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 246/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 247/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 248/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 249/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 250/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 251/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 252/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 253/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 254/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 255/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 256/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 257/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 258/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 259/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 260/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 261/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 262/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 263/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 264/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 265/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 266/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 267/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 268/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 269/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 270/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 271/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 272/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 273/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 274/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 275/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 276/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 277/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 278/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 279/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 280/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 281/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 282/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 283/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 284/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 285/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 286/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 287/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 288/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 289/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 290/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 291/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 292/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 293/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 294/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 295/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 296/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 297/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 298/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 299/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 300/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 301/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 302/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 303/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 304/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 305/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 306/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 307/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 308/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 309/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 310/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 311/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 312/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 313/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 314/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 315/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 316/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 317/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 318/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 319/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 320/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 321/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 322/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 323/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 324/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 325/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 326/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 327/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 328/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 329/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0071\n",
      "Epoch 330/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 331/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 332/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 333/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 334/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 335/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 336/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 337/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 338/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 339/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 340/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 341/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 342/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 343/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 344/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 345/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 346/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 347/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 348/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 349/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 350/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 351/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 352/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 353/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 354/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 355/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 356/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 357/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 358/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 359/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 360/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 361/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 362/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 363/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 364/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 365/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 366/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 367/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 368/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 369/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 370/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 371/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 372/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 373/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 374/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 375/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 376/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 377/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 378/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 379/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 380/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 381/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 382/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 383/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 384/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 385/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 386/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 387/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 388/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 389/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 390/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 391/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 392/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 393/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 394/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 395/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 396/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 397/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 398/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 399/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 400/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 401/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 402/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 403/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 404/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 405/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 406/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 407/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 408/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 409/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 410/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 411/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 412/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 413/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 414/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 415/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 416/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 417/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 418/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 419/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 420/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 421/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 422/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 423/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 424/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 425/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 426/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 427/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 428/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 429/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 430/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 431/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 432/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 433/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 434/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 435/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 436/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 437/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 438/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 439/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 440/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 441/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 442/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 443/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 444/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 445/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 446/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 447/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 448/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 449/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 450/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 451/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 452/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 453/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 454/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 455/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 456/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 457/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 458/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 459/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 460/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 461/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 462/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 463/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 464/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 465/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 466/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 467/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 468/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 469/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 470/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 471/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 472/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 473/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 474/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 475/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 476/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 477/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 478/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 479/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 480/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 481/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 482/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 483/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 484/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 485/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 486/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 487/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 488/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 489/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 490/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 491/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 492/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 493/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 494/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 495/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 496/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 497/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 498/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 499/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 500/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 501/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 502/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 503/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 504/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 505/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 506/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 507/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 508/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 509/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 510/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 511/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 512/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 513/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 514/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 515/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 516/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 517/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 518/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 519/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 520/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 521/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 522/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 523/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 524/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 525/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 526/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 527/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 528/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 529/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 530/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 531/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 532/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 533/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 534/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 535/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 536/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 537/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 538/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 539/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 540/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 541/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 542/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 543/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 544/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 545/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 546/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 547/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 548/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 549/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 550/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 551/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 552/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 553/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 554/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 555/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 556/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 557/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 558/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 559/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 560/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 561/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 562/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 563/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 564/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 565/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 566/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 567/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 568/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 569/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 570/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 571/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 572/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 573/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 574/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 575/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 576/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 577/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 578/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 579/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 580/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 581/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 582/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 583/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 584/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 585/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 586/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 587/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 588/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 589/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 590/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 591/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 592/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 593/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 594/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 595/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 596/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 597/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 598/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 599/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 600/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 601/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 602/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 603/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 604/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 605/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 606/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 607/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 608/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 609/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 610/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 611/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 612/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 613/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 614/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 615/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 616/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 617/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 618/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0072\n",
      "Epoch 619/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 620/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 621/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 622/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 623/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 624/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 625/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 626/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 627/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 628/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 629/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 630/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 631/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 632/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 633/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 634/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 635/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 636/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 637/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 638/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 639/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 640/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 641/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0071\n",
      "Epoch 642/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 643/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 644/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 645/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 646/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 647/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 648/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 649/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 650/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 651/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 652/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 653/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 654/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 655/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 656/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 657/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 658/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 659/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 660/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 661/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 662/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 663/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 664/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 665/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 666/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 667/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 668/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 669/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 670/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 671/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 672/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 673/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 674/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 675/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 676/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 677/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 678/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 679/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 680/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 681/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 682/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 683/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 684/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 685/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 686/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 687/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 688/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 689/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 690/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 691/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 692/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 693/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 694/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 695/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 696/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 697/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 698/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 699/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 700/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 701/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 702/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 703/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 704/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 705/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 706/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 707/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 708/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 709/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 710/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 711/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 712/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 713/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 714/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 715/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 716/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 717/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 718/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 719/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 720/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 721/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 722/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 723/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 724/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 725/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 726/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 727/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 728/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 729/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 730/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 731/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 732/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 733/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 734/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 735/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 736/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 737/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 738/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 739/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 740/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 741/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 742/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 743/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 744/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 745/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 746/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 747/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 748/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 749/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 750/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 751/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 752/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 753/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 754/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 755/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 756/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 757/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 758/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 759/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 760/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 761/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 762/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 763/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 764/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 765/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 766/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 767/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 768/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 769/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 770/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 771/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 772/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 773/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 774/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 775/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 776/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 777/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 778/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 779/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 780/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 781/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 782/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 783/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 784/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 785/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 786/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 787/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 788/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 789/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 790/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 791/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 792/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 793/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 794/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 795/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 796/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 797/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 798/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 799/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 800/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 801/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 802/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 803/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 804/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 805/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 806/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 807/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 808/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 809/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 810/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 811/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 812/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 813/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 814/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 815/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 816/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 817/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 818/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 819/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 820/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 821/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 822/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 823/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 824/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 825/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 826/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 827/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 828/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 829/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 830/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 831/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 832/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 833/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 834/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 835/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 836/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 837/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 838/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 839/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 840/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 841/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 842/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 843/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 844/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 845/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 846/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 847/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 848/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 849/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 850/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 851/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 852/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 853/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 854/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 855/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 856/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 857/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 858/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 859/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 860/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 861/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 862/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 863/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 864/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 865/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 866/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 867/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 868/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 869/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 870/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 871/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 872/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 873/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 874/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 875/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 876/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 877/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 878/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 879/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 880/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 881/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 882/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 883/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 884/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 885/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 886/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 887/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 888/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 889/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 890/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 891/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 892/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 893/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 894/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 895/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 896/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 897/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 898/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 899/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 900/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 901/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 902/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 903/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 904/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 905/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 906/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 907/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 908/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 909/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 910/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 911/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 912/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 913/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 914/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 915/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 916/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 917/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 918/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 919/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 920/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 921/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 922/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 923/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 924/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 925/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 926/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 927/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 928/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 929/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 930/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 931/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 932/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 933/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 934/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 935/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 936/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 937/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 938/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 939/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 940/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 941/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 942/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 943/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 944/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 945/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 946/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 947/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 948/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 949/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 950/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 951/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 952/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 953/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 954/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 955/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 956/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 957/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 958/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 959/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 960/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 961/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 962/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 963/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 964/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 965/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 966/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 967/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 968/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 969/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 970/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 971/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 972/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 973/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 974/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 975/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 976/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 977/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 978/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 979/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 980/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 981/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 982/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 983/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 984/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 985/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 986/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 987/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 988/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 989/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 990/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 991/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 992/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 993/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 994/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 995/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 996/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 997/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 998/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 999/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 1000/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "score: test score =  0.006824963726103306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/rnn-lstm-so2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/rnn-lstm-so2/assets\n"
     ]
    }
   ],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "# model.add(LSTM(4, input_shape=(1, look_back), return_sequences=True))\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "history = model.fit(trainX, trainY, epochs=1000, batch_size=10, verbose=2,\n",
    "          validation_data=(testX, testY))\n",
    "\n",
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print('score: test score = ', score)\n",
    "\n",
    "# save the model\n",
    "model.save('models/rnn-lstm-'+product_name)\n",
    "# save the scaler\n",
    "dump(scaler, open('models/rnn-lstm-'+product_name+'/scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f856b5a70d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_Y = testY[0][len(testY[0])-15:len(testY[0])-1]\n",
    "test_Ypred = testPredict[len(testPredict)-15:len(testPredict)-1]\n",
    "plt.subplots(figsize=(10, 5))\n",
    "plt.title(product_name.upper() + \" - Forecast vs Actual\", fontsize=14)\n",
    "plt.plot(pd.Series(numpy.ravel(test_Y)), \"bs-\", markersize=3, label=\"Actual\")\n",
    "plt.plot(pd.Series(numpy.ravel(test_Ypred)), \"ro-\", markersize=3, label=\"Forecast\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylim([-0.01,0.01])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00015354 RMSE\n",
      "Test Score: 0.00011530 RMSE\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.8f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.8f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot baseline and predictions\n",
    "# plt.plot(scaler.inverse_transform(dataset),\"b-\", label=\"Actual\")\n",
    "# plt.plot(trainPredictPlot,\"y-\", label=\"Train pred\")\n",
    "# plt.plot(scaler.inverse_transform(testY)[0],\"b-\", label=\"Actual\")\n",
    "# plt.plot(testPredictPlot, \"g-\", label=\"Test pred\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.ylim([-0.02,0.02])\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18f9e42b91da9395310def41b953de3eaf324ff700d0d0be600380b7bf53ba90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
