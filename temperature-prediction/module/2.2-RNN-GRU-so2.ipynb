{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Prediction with GRU\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    " dataX, dataY = [], []\n",
    " for i in range(len(dataset)-look_back-1):\n",
    "  a = dataset[i:(i+look_back), 0]\n",
    "  dataX.append(a)\n",
    "  dataY.append(dataset[i + look_back, 0])\n",
    " return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: \n",
      "             date dist        co       no2        o3  so2  ch4      hcho\n",
      "0     2018-04-30   q1  0.036519  0.000059  0.127509  0.0    0  0.000000\n",
      "1     2018-05-01   q1  0.035765  0.000053  0.128756  0.0    0  0.000000\n",
      "2     2018-05-02   q1  0.037218  0.000051  0.127053  0.0    0  0.000000\n",
      "3     2018-05-03   q1  0.000000  0.000000  0.120879  0.0    0  0.000000\n",
      "4     2018-05-04   q1  0.000000  0.000000  0.121712  0.0    0  0.000000\n",
      "...          ...  ...       ...       ...       ...  ...  ...       ...\n",
      "1281  2021-11-01   q1  0.032100  0.000000  0.120907  0.0    0  0.000000\n",
      "1282  2021-11-02   q1  0.000000  0.000239  0.115687  0.0    0  0.000239\n",
      "1283  2021-11-03   q1  0.030268  0.000000  0.115781  0.0    0  0.000000\n",
      "1284  2021-11-04   q1  0.028053  0.000200  0.116181  0.0    0  0.000200\n",
      "1285  2021-11-05   q1  0.000000  0.000000  0.111895  0.0    0  0.000000\n",
      "\n",
      "[1286 rows x 8 columns]\n",
      "Dataset: \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"q1\"\n",
    "product_name = \"so2\"\n",
    "file_path = 'dataset/'+dataset_name+'.csv'\n",
    "dataframe = pd.read_csv(file_path)\n",
    "print(\"Dataframe: \\n\", dataframe)\n",
    "dataset = numpy.asarray(dataframe[product_name]).reshape(-1,1)\n",
    "print(\"Dataset: \\n\", dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after scale: \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "print(\"Dataset after scale: \\n\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.9)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainX shape:  (1155, 1)\n",
      "TrainY shape:  (1155,)\n"
     ]
    }
   ],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "print(\"TrainX shape: \", trainX.shape)\n",
    "print(\"TrainY shape: \", trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 4)                 84        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "116/116 - 4s - loss: 0.0123 - val_loss: 0.0066\n",
      "Epoch 2/1000\n",
      "116/116 - 0s - loss: 0.0123 - val_loss: 0.0068\n",
      "Epoch 3/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 4/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 5/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 6/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 7/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 8/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 9/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 10/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 11/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 12/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 13/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 14/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 15/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 16/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 17/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 18/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 19/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 20/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 21/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 22/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 23/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 24/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 25/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 26/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 27/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 28/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 29/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 30/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 31/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 32/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 33/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 34/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 35/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 36/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 37/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 38/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 39/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 40/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0073\n",
      "Epoch 41/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 42/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 43/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 44/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 45/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 46/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 47/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 48/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 49/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 50/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 51/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 52/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 53/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 54/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 55/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 56/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 57/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 58/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 59/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 60/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 61/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 62/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 63/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 64/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 65/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 66/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 67/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 68/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 69/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 70/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 71/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 72/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 73/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 74/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 75/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 76/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 77/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 78/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 79/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 80/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 81/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 82/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 83/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 84/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 85/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 86/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 87/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 88/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 89/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 90/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 91/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 92/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 93/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 94/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 95/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 96/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 97/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 98/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 99/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 100/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 101/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 102/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 103/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 104/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 105/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 106/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 107/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 108/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 109/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 110/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 111/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 112/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 113/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 114/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 115/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 116/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 117/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 118/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 119/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 120/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 121/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 122/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 123/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 124/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 125/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 126/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 127/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 128/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 129/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 130/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 131/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 132/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 133/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0071\n",
      "Epoch 134/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 135/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 136/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 137/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 138/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 139/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 140/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 141/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 142/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 143/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 144/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 145/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 146/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 147/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 148/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 149/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 150/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 151/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 152/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 153/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 154/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 155/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 156/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 157/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 158/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 159/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 160/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 161/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 162/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 163/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 164/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 165/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 166/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 167/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 168/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 169/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 170/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 171/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 172/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 173/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 174/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 175/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 176/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 177/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 178/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 179/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 180/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0071\n",
      "Epoch 181/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 182/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 183/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 184/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 185/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 186/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 187/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 188/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 189/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 190/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 191/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 192/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 193/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 194/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 195/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 196/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 197/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 198/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 199/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 200/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 201/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 202/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 203/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0071\n",
      "Epoch 204/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 205/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 206/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 207/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 208/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 209/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 210/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 211/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 212/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 213/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 214/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 215/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 216/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 217/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 218/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 219/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 220/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 221/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 222/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 223/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 224/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 225/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 226/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 227/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 228/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 229/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 230/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 231/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 232/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 233/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 234/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 235/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 236/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 237/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 238/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 239/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 240/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 241/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 242/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 243/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 244/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 245/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 246/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 247/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 248/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 249/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 250/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 251/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 252/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 253/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 254/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0071\n",
      "Epoch 255/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 256/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 257/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 258/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 259/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 260/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 261/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 262/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 263/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 264/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 265/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 266/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 267/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 268/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 269/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 270/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 271/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 272/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 273/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 274/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 275/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 276/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 277/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 278/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 279/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 280/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 281/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 282/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 283/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0071\n",
      "Epoch 284/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 285/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 286/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 287/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 288/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 289/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 290/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 291/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 292/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 293/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 294/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 295/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 296/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 297/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 298/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 299/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 300/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 301/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 302/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 303/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 304/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 305/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 306/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 307/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 308/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 309/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 310/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 311/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 312/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 313/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 314/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 315/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 316/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 317/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 318/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 319/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 320/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 321/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 322/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 323/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 324/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 325/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 326/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 327/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 328/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 329/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 330/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 331/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 332/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 333/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 334/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 335/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 336/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 337/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 338/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 339/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 340/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 341/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 342/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 343/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 344/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 345/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 346/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 347/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 348/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 349/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 350/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 351/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 352/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 353/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 354/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 355/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 356/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 357/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 358/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 359/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 360/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 361/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 362/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 363/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 364/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 365/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 366/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 367/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 368/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 369/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 370/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 371/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 372/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 373/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 374/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 375/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 376/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 377/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 378/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 379/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 380/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 381/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 382/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 383/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 384/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 385/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 386/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 387/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 388/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 389/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 390/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 391/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 392/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 393/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 394/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 395/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 396/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 397/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 398/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 399/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 400/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 401/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 402/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 403/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 404/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 405/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 406/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 407/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 408/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 409/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 410/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 411/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 412/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 413/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 414/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 415/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 416/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 417/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 418/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 419/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 420/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 421/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 422/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 423/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 424/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 425/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 426/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 427/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 428/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 429/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 430/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 431/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 432/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 433/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 434/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 435/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 436/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 437/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 438/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 439/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 440/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 441/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 442/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 443/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 444/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 445/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 446/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 447/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 448/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 449/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 450/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 451/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 452/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 453/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 454/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 455/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 456/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 457/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 458/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 459/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 460/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 461/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 462/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 463/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 464/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 465/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 466/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 467/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 468/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 469/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 470/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 471/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 472/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 473/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 474/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 475/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 476/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 477/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 478/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 479/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 480/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 481/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 482/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 483/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 484/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 485/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 486/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 487/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 488/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 489/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 490/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 491/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 492/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 493/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 494/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 495/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 496/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 497/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 498/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 499/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 500/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 501/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 502/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 503/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 504/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 505/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 506/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 507/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 508/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 509/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 510/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 511/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 512/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 513/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 514/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 515/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 516/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 517/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 518/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 519/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 520/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 521/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 522/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 523/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 524/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 525/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 526/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 527/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 528/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 529/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 530/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 531/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 532/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 533/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 534/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 535/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 536/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 537/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 538/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 539/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 540/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 541/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 542/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 543/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 544/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 545/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 546/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 547/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 548/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 549/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 550/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 551/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 552/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 553/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 554/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 555/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 556/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 557/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 558/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 559/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 560/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 561/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 562/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 563/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 564/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 565/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 566/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 567/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 568/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 569/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 570/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 571/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 572/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 573/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 574/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 575/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 576/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 577/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 578/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 579/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 580/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 581/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 582/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 583/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 584/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 585/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 586/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 587/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 588/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 589/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 590/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 591/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 592/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 593/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 594/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 595/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 596/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 597/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 598/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 599/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 600/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 601/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 602/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 603/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 604/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 605/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 606/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 607/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 608/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 609/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 610/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 611/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 612/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 613/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 614/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 615/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 616/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 617/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 618/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 619/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 620/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 621/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 622/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 623/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 624/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 625/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 626/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 627/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 628/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 629/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 630/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 631/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 632/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 633/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 634/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 635/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 636/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 637/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 638/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 639/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 640/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 641/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 642/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 643/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 644/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 645/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 646/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 647/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 648/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 649/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 650/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 651/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 652/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 653/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 654/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 655/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 656/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 657/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 658/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 659/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 660/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 661/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 662/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 663/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 664/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 665/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 666/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 667/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 668/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 669/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 670/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 671/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 672/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 673/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 674/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 675/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 676/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 677/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 678/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 679/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 680/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 681/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 682/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 683/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 684/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 685/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 686/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 687/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 688/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 689/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 690/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 691/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 692/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 693/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 694/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 695/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 696/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 697/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 698/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 699/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 700/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 701/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 702/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 703/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 704/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 705/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 706/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 707/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 708/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 709/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 710/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 711/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 712/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 713/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 714/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 715/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 716/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 717/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 718/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 719/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 720/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 721/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 722/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 723/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 724/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 725/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 726/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 727/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 728/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 729/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 730/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 731/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 732/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 733/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 734/1000\n",
      "116/116 - 1s - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 735/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 736/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 737/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 738/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 739/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 740/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 741/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 742/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 743/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 744/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 745/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 746/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 747/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 748/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 749/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 750/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 751/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 752/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 753/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 754/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 755/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 756/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 757/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 758/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 759/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 760/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 761/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 762/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 763/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 764/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 765/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 766/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 767/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 768/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 769/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 770/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 771/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 772/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 773/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 774/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 775/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 776/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 777/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 778/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 779/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 780/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 781/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 782/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 783/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 784/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 785/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 786/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 787/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 788/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 789/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 790/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 791/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 792/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 793/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 794/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 795/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 796/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 797/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 798/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 799/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 800/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 801/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 802/1000\n",
      "116/116 - 1s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 803/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 804/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 805/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 806/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 807/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 808/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 809/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 810/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 811/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 812/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 813/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 814/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 815/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 816/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 817/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 818/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 819/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 820/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 821/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 822/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 823/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 824/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 825/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 826/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 827/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 828/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 829/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 830/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 831/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 832/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 833/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 834/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 835/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 836/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 837/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 838/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 839/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 840/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 841/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 842/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 843/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 844/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 845/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 846/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 847/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 848/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 849/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 850/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 851/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 852/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 853/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 854/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 855/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 856/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 857/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 858/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 859/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 860/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 861/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 862/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 863/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 864/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 865/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 866/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 867/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 868/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 869/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 870/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 871/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 872/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 873/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 874/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 875/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 876/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 877/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 878/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 879/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 880/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 881/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 882/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 883/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 884/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 885/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 886/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 887/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 888/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 889/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 890/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 891/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 892/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 893/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 894/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 895/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 896/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 897/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 898/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 899/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 900/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 901/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 902/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 903/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 904/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 905/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 906/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 907/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 908/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 909/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 910/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 911/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 912/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 913/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 914/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 915/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 916/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 917/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 918/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 919/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 920/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 921/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 922/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 923/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 924/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 925/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 926/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 927/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 928/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 929/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 930/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 931/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 932/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 933/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 934/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 935/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 936/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 937/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 938/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 939/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 940/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 941/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 942/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 943/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 944/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 945/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 946/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 947/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 948/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 949/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 950/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 951/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 952/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 953/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 954/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 955/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 956/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 957/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 958/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 959/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 960/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 961/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 962/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 963/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 964/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 965/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 966/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 967/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 968/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 969/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 970/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 971/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 972/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 973/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 974/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 975/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 976/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 977/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 978/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 979/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 980/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 981/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 982/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 983/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 984/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 985/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 986/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 987/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 988/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 989/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 990/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 991/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 992/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 993/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 994/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 995/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 996/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 997/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 998/1000\n",
      "116/116 - 0s - loss: 0.0122 - val_loss: 0.0068\n",
      "Epoch 999/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 1000/1000\n",
      "116/116 - 0s - loss: 0.0121 - val_loss: 0.0067\n",
      "score: test score =  0.006674180738627911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/rnn-GRU-so2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/rnn-GRU-so2/assets\n"
     ]
    }
   ],
   "source": [
    "# create and fit the GRU network\n",
    "model = Sequential()\n",
    "# model.add(GRU(4, input_shape=(1, look_back), return_sequences=True))\n",
    "model.add(GRU(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "history = model.fit(trainX, trainY, epochs=1000, batch_size=10, verbose=2,\n",
    "          validation_data=(testX, testY))\n",
    "\n",
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print('score: test score = ', score)\n",
    "\n",
    "# save the model\n",
    "model.save('models/rnn-GRU-'+product_name)\n",
    "# save the scaler\n",
    "dump(scaler, open('models/rnn-GRU-'+product_name+'/scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd7a466fa00>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAFOCAYAAAA/7JG4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAueklEQVR4nO3de5wdZZ3v+88v3R3CJUICAQMhJrgDQgQi9OaiYIKABkUC47CBg3LRPRG3qOjoCHKGzXjOUUZHB1EEGUQQIYAoEBVlEAEdDUIC2chFJNybhAABQiCEpDu/80dVJyuLvqV7QXeFz/v1qtdaVfU8Tz1VSae/eeoWmYkkSZKGvmGD3QFJkiT1jcFNkiSpIgxukiRJFWFwkyRJqgiDmyRJUkUY3CRJkirC4CZJGnQRkRHx94PdD2moM7hJbyIRMSYivh8Rj0bEqxGxOCJuioiD68q9IyJmletfjYhHIuJbETGqpkxLRPxrRNwdES9HxKKIuDwixjeor9nFNL8RbQ+WiDghIl4a5D7MjoiO+j/zPtSbVv4ZbPV69U1S7wxu0pvLz4C9gE8AOwKHAr8GtuwsEBF7AbcDI4HDgUnAZ4BDgD9FxBZl0U2APYD/r/ycAWwP/CYimhvU338AxtZMB/a3oYhoaVCfKisiOo/hvwP/c5C7I6k/MtPJyelNMAFbAAkc1EOZAO4B5gHD6tZtC7wMnNtD/V3KbezagP4m8PfdrBsG/DPwBPAq8BdgRs36CWX9Y4DfAa8AJ5frTgTuA1YAfwM+X7uvwFuA84BFZZn7gaPKdVsCs4C2ss17gRPr+vZe4DbgJWAp8GfgncC0sk+105ld7NvmZdsfrlv+fmAVsHU5fwbwWLn/TwE/7sMxPY0ivI8vt7Fl3frhwNdq2n0Y+GzN8aydLi7r3AJ8r66di4Ff1sxPB/4APA88B9wA7NzXP28nJ6e1kyNu0pvHS+V0WESM6KbMFGAy8K3MXF27IjMXApcDx0REdFP/LeXn8wPvbo8+B3wJ+DKwK3AN8POImFJX7uvA9ykC5bUR8Q8UweQMYGfgH8s2/hdAuV+/BqZSBLxdgC8AK8v2RgB3UoxUTga+A/wgIg4s6zcD1wH/BewO7F2W6QD+BJwCLGftCOK/1e9YZi4FfgkcW7fqWOA/M/PpiPgI8MWy35PK/tze0wEr9+3jwE8y83GKQPmxumKXAMeV+7wzxcjsCxQB+SNlmcll3z/X0/bqbAqcTTHaO40i0P4iIoavRxuSwBE3J6c300Txy/c5ipGkORTBYe+a9UdRjHy8q5v6ny/Xb93FuuHAH4HZDeprUowKvVQzHVuuexI4o678LRShBNaOEP1jXZnHgY/VLTsFuK/8fjCwmrrRoF76eQVwYfl9dLndqd2UPQF4qQ9tzqAIeCPL+Y2BF4FjyvkvAA8ALevRzwOAJcDwcv7jwF9q1k8q+z69m/rTyvVbdXHcexxx66KtTSnC7H51f96OuDk59TI54ia9iWTmzyhOeX6YYmTp3cBtEfGV+qLdNBFdrS9Hmn5CcTr2xO62HxHjI+Klmql+u/W+RDEK2DnNjoi3lPvwx7qy/0UxQlZrbs22x1Bcg/eD2j4AZwFvL4u9C1iUmfd30/+miDi9vCFjSVn/7yhOPZKZz1GElhsi4lcR8YWI2L6XfezK9RTB7Yhy/jCKY39dOf9TitG/RyLihxFxZERs1EubnwCuyszO0cOrgbdHxN7l/LsoQuvN/ehvjyLi7eWNKw9FxIvAYorT3Q25kUV6MzG4SW8ymbkiM2/MzK9m5ruBHwJnlqet/lYWm9xN9Z0pToM+27mgDG2zgN2AAzNzSQ+bX8i6Qez8Xrr7VGYuqJmW1e5KV7tXN/9yzffOf+9OquvDO1m7v92dAu70RYrTq9+kuMh/CnAtxWhj0YHMEylOkf6eInD9LSI+0Eu768jMVRThrPN06bHAzzNzebn+CWAn4JMUI3HfAuZFxKZdtVfeUPIRYGZEtEdEO8XI68asvUmht33vzuou6tbfCPILYEzZ370pQmI7NcdNUt8Y3CTdBzRTjODMp7gY/wsRsc6/DxGxLUWAmJWZWS5rAa6kCG0HZOZTPW0oM9vrgthz69vZzHyRIgDuV7dqv3Jfuqu3mOIU69vr+rAgMxeUxe4ExkbEzt00sx/wi8y8NDPnAw9R3J1bv63/k5n/mpnTKE4lHl+uWgk09WE3oRjBPDAidqG4uP8nddtYkZm/yszPA/+dIny+p5u2jgWeobjubkrNNBM4qgx8d1L8TjigmzY6R+rq+/8MxTVvtXbv/BIRW1IE/q9l5m/L0cyRFH/nJK0nf3CkN4nyF+hPgYuAu4FlQCvwT8BNZSAiIj4O/Ba4LiK+RnEH5W4Uo0yPAf93Wa65bO+/U5x6zYh4a7m5pZn5yuu4O98EvhoRD1LcAftRYH9gz17qnQl8NyJeoDgd2ULxKJPtMvPrwE0UF+3/LCI+TzEC+d+ATTPz2nL+qIjYj2LU8TPAROAugIiYSDGqNJsiJO5AcezOK7f/KDCifIbaXcDyzlG0epn5x4h4jOKGkGcp7o6l3M4JFP9+/5ni2r+jKO44fbCb/f4EcHVm3lO7MCL+RnEsj8rMiyLiKuDCiPgcRZAbB0zIzEsp/uwT+FBE/AJ4JTNfKvt1dkQcRnHd3ScpTkk/Wm6mc4T2HyLiCWC7cpvt3fRVUk8G+yI7JyenN2YCNqK4o/IOil+myyl+0X8bGF1XdheKi+6fphhpebQsN6qmzARe+4iIzumEBvS3r48DWUnxOJDDu+hbaxd1j6EIJSvK4/BfwNE167cA/oNiJGkFxSje/yjXjQJ+ThF6nwa+QXHX6i3l+m3K9U9SPE7j8bJMS03751EEmS4fB1LX16+W5b5Vt/xwiptLXqA4HXwHcGg3bexRtvHubtb/GPhTzd+Rb9T0/yHKx6iU6/+Z4jEpq1n7OJAW4Nxyn54t+3wx6z4O5H0Uj5lZUX5+gCJwnlBTxpsTnJz6MEVmd9cgS5IkaSjxGjdJkqSKaEhwi4jpEfFARCyIiFO7WB8RcU65/u6I2KNm3UUR8XRE1F97MToiboyIB8vP2ncknla29cD63q0lSZJUVQMObhHRRHF9wyEU18UcU94FVesQioc7TqK4i+m8mnUXU9wxVe9UigumJ1FcMHxqub1dgKMp7qCaDny/7IMkSdIGrREjbnsBCzLz4Swe7HgFxVO/a82geI9eZuZtwBbly47JzN9TPE+o3gyK169Qfh5es/yKzHw1Mx8BFpR9kCRJ2qA1IrhtR3FnV6e2ctn6lqm3TWYuAig/tx5AW5IkSZXXiOe4dfW07fpbVftSppHbKwpGzKQ4Ncumm2665zve8Y5+blKSJOmNM2/evGczc0z98kYEtzaKhy12GkfxVPP1LVNvcUSMzcxF5WnVp9e3rcy8ALgAoLW1NefOndtVMUmSpCGlfAD3azTiVOkdwKSImFi+6/BoiqeG15oNHFfeXboPxVPVF/XS7mzWvibmeNa+XHk2cHREbFQ+pXwScHsD9kOSJGlIG/CIW2a2R8TJwA0U77C7KDPvjYiTyvXnU7xa5oMUNxIsB07srB8Rs4BpwFYR0Qb878z8IXAWcFVEfILi6eNHlu3dW76W5T6KV6Z8OjM7BrofkiRJQ92b5s0JniqVJElVERHzMrO1frkvmZckSQ2xatUq2traWLFixWB3pTJGjBjBuHHjaGlp6VN5g5skSWqItrY2Ro4cyYQJE4jo6iEQqpWZLFmyhLa2NiZOnNinOr6rVJIkNcSKFSvYcsstDW19FBFsueWW6zVCaXCTJEkNY2hbP+t7vAxukiRpg3LNNdcQEfz1r3/tsdzZZ5/N8uXL+72diy++mJNPPrnf9fvD4CZJkjYos2bNYr/99uOKK67osdxAg9tgMLhJkqQNxksvvcQf//hHfvjDH64Jbh0dHXzxi19k1113ZbfdduO73/0u55xzDgsXLuSAAw7ggAMOAGCzzTZb087VV1/NCSecAMAvfvEL9t57b971rndx0EEHsXjx4jd8vzp5V6kkSdpgXHvttUyfPp0dd9yR0aNHc+edd/LnP/+ZRx55hLvuuovm5maee+45Ro8ezbe//W1uvvlmttpqqx7b3G+//bjtttuICC688EK+8Y1v8K1vfesN2qN1GdwkSVLDnXIKzJ/fe7k//QlWrSq+t7TAu9/dfdkpU+Dss3tub9asWZxyyikAHH300cyaNYuHH36Yk046iebmIvaMHj26947VaGtr46ijjmLRokWsXLmyz4/ueD0Y3CRJ0qDpDG313/tjyZIl/O53v+Oee+4hIujo6CAi2HPPPft092ZtmdpHdHzmM5/hC1/4Aocddhi33HILZ5555sA6OgAGN0mS1HC9jYx1qs9Tt9zS/21effXVHHfccfzgBz9Ys2zq1KnssccenH/++UybNm2dU6UjR45k2bJla06VbrPNNtx///3stNNOXHPNNYwcORKApUuXst122wFwySWX9L+DDeDNCZIkadBss03X3/tj1qxZHHHEEess+8hHPsLChQsZP348u+22G7vvvjuXX345ADNnzuSQQw5Zc3PCWWedxaGHHsr73vc+xo4du6aNM888kyOPPJL999+/1+vhXm++ZF6SJDXE/fffz8477zzY3aicro5bdy+Zd8RNkiSpIgxukiRJFWFwkyRJqgiDmyRJUkUY3CRJkirC4CZJklQRBjdJkrTBaGpqYsqUKWumRx99dLC7BMDZZ5/N8uXLB9yOb06QJEkbjI033pj5fXlJap329vY17zJ9PZx99tl89KMfZZNNNhlQO464SZKkDdr8+fPZZ5992G233TjiiCN4/vnnAZg2bRpf+cpXmDp1Kt/5zneYN28eU6dOZc899+QDH/gAixYtAmDBggUcdNBB7L777uyxxx489NBDvPTSSxx44IHsscce7Lrrrlx33XUAvPzyy3zoQx9i9913553vfCdXXnkl55xzDgsXLuSAAw5Y85aG/nLETZIkDZ45c4oXlE6bBvvuO+DmXnnlFaZMmQLAxIkTueaaazjuuOP47ne/y9SpUznjjDP4l3/5F84uX6b6wgsvcOutt7Jq1SqmTp3Kddddx5gxY7jyyis5/fTTueiiizj22GM59dRTOeKII1ixYgWrV69m+PDhXHPNNbzlLW/h2WefZZ999uGwww7jN7/5Ddtuuy2/+tWvgOI9p5tvvjnf/va3ufnmmwf8yiyDmyRJarxTToHeTlkuXQp33w2rV8OwYbDbbrD55t2XnzKl17fX158qXbp0KS+88AJTp04F4Pjjj+fII49cs/6oo44C4IEHHuCee+7h4IMPBqCjo4OxY8eybNkynnzyyTXvQB0xYgQAq1at4itf+Qq///3vGTZsGE8++SSLFy9m11135Ytf/CJf/vKXOfTQQ9l///17PgbryeAmSZIGx9KlRWiD4nPp0p6D2+tg0003BSAzmTx5MnPmzFln/Ysvvthlvcsuu4xnnnmGefPm0dLSwoQJE1ixYgU77rgj8+bN4/rrr+e0007j/e9/P2eccUbD+tuQ4BYR04HvAE3AhZl5Vt36KNd/EFgOnJCZd/ZUNyKuBHYqm9gCeCEzp0TEBOB+4IFy3W2ZeVIj9kOSJDVILyNjQHGa9MADYeVKGD4cLrusIadLa22++eaMGjWKP/zhD+y///5ceumla0bfau20004888wzzJkzh3333ZdVq1bxt7/9jcmTJzNu3DiuvfZaDj/8cF599VU6OjpYunQpW2+9NS0tLdx888089thjACxcuJDRo0fz0Y9+lM0224yLL74YgJEjR7Js2bLBP1UaEU3AucDBQBtwR0TMzsz7aoodAkwqp72B84C9e6qbmUfVbONbwNKa9h7KzCkD7bskSRpE++4LN93U0GvcunLJJZdw0kknsXz5cnbYYQd+9KMfvabM8OHDufrqq/nsZz/L0qVLaW9v55RTTmHy5MlceumlfPKTn+SMM86gpaWFn/70pxx77LF8+MMfprW1lSlTpvCOd7wDgL/85S986UtfYtiwYbS0tHDeeecBMHPmTA455BDGjh3LzTff3O99iczsd2WAiNgXODMzP1DOnwaQmV+vKfMD4JbMnFXOPwBMAyb0oW4AjwPvy8wHyxG3X2bmO9enn62trTl37tx+7qUkSerN/fffz8477zzY3aicro5bRMzLzNb6so14HMh2wBM1823lsr6U6Uvd/YHFmflgzbKJEXFXRNwaEY296k+SJGmIasQ1btHFsvphvO7K9KXuMcCsmvlFwPjMXBIRewLXRsTkzHzN1YMRMROYCTB+/Phuui9JklQNjRhxawO2r5kfByzsY5ke60ZEM/B3wJWdyzLz1cxcUn6fBzwE7NhVxzLzgsxszczWMWPGrOduSZIkDS2NCG53AJMiYmJEDAeOBmbXlZkNHBeFfYClmbmoD3UPAv6amW2dCyJiTHlTAxGxA8UNDw83YD8kSdIADfTa+Teb9T1eAz5VmpntEXEycAPFIz0uysx7I+Kkcv35wPUUjwJZQPE4kBN7qlvT/NGse5oU4L3AVyOiHegATsrM5wa6H5IkaWBGjBjBkiVL2HLLLSnuLVRPMpMlS5aseahvXwz4rtKq8K5SSZJeX6tWraKtrY0VK1YMdlcqY8SIEYwbN46WlpZ1lnd3V6lvTpAkSQ3R0tLCxIkTB7sbG7RGXOMmSZKkN4DBTZIkqSIMbpIkSRVhcJMkSaoIg5skSVJFGNwkSZIqwuAmSZJUEQY3SZKkijC4SZIkVYTBTZIkqSIMbpIkSRVhcJMkSaoIg5skSVJFGNwkSZIqwuAmSZJUEQY3SZKkijC4SZIkVYTBTZIkqSIMbpIkSRVhcJMkSaoIg5skSVJFGNwkSZIqwuAmSZJUEQY3SZKkimhIcIuI6RHxQEQsiIhTu1gfEXFOuf7uiNijt7oRcWZEPBkR88vpgzXrTivLPxARH2jEPkiSJA11zQNtICKagHOBg4E24I6ImJ2Z99UUOwSYVE57A+cBe/eh7r9n5r/VbW8X4GhgMrAt8NuI2DEzOwa6L5IkSUNZI0bc9gIWZObDmbkSuAKYUVdmBvDjLNwGbBERY/tYt94M4IrMfDUzHwEWlO1IkiRt0BoR3LYDnqiZbyuX9aVMb3VPLk+tXhQRo9Zje5IkSRucRgS36GJZ9rFMT3XPA94OTAEWAd9aj+0VBSNmRsTciJj7zDPPdFVEkiSpMhoR3NqA7WvmxwEL+1im27qZuTgzOzJzNfAfrD0d2pftUbZxQWa2ZmbrmDFj1munJEmShppGBLc7gEkRMTEihlPcODC7rsxs4Ljy7tJ9gKWZuainuuU1cJ2OAO6paevoiNgoIiZS3PBwewP2Q5IkaUgb8F2lmdkeEScDNwBNwEWZeW9EnFSuPx+4HvggxY0Ey4ETe6pbNv2NiJhCcRr0UeCTZZ17I+Iq4D6gHfi0d5RKkqQ3g8js8vKwDU5ra2vOnTt3sLshSZLUq4iYl5mt9ct9c4IkSVJFGNwkSZIqwuAmSZJUEQY3SZKkijC4SZIkVYTBTZIkqSIMbpIkSRVhcJMkSaoIg5skSVJFGNwkSZIqwuAmSZJUEQY3SZKkijC4SZIkVYTBTZIkqSIMbpIkSRVhcJMkSaoIg5skSVJFGNwkSZIqwuAmSZJUEQY3SZKkijC4SZIkVYTBTZIkqSIMbpIkSRVhcJMkSaoIg5skSVJFNCS4RcT0iHggIhZExKldrI+IOKdcf3dE7NFb3Yj4ZkT8tSx/TURsUS6fEBGvRMT8cjq/EfsgSZI01A04uEVEE3AucAiwC3BMROxSV+wQYFI5zQTO60PdG4F3ZuZuwN+A02raeygzp5TTSQPdB0mSpCpoxIjbXsCCzHw4M1cCVwAz6srMAH6chduALSJibE91M/M/M7O9rH8bMK4BfZUkSaqsRgS37YAnaubbymV9KdOXugAfB35dMz8xIu6KiFsjYv/+dlySJKlKmhvQRnSxLPtYpte6EXE60A5cVi5aBIzPzCURsSdwbURMzswXX9OxiJkUp2YZP358jzshSZI01DVixK0N2L5mfhywsI9leqwbEccDhwLHZmYCZOarmbmk/D4PeAjYsauOZeYFmdmama1jxozpx65JkiQNHY0IbncAkyJiYkQMB44GZteVmQ0cV95dug+wNDMX9VQ3IqYDXwYOy8zlnQ1FxJjypgYiYgeKGx4ebsB+SJIkDWkDPlWame0RcTJwA9AEXJSZ90bESeX684HrgQ8CC4DlwIk91S2b/h6wEXBjRADcVt5B+l7gqxHRDnQAJ2XmcwPdD0mSpKEuyjOQG7zW1tacO3fuYHdDkiSpVxExLzNb65f75gRJkqSKMLhJkiRVhMFNkiSpIgxukiRJFWFwkyRJqgiDmyRJUkUY3CRJkirC4CZJklQRBjdJkqSKMLhJkiRVhMFNkiSpIgxukiRJFWFwkyRJqgiDmyRJUkUY3CRJkirC4CZJklQRBjdJkqSKMLhJkiRVhMFNkiSpIgxukiRJFWFwkyRJqgiDmyRJUkUY3CRJkirC4KY31OrV8NRT8Oc/w09/CiNHQkQxbbklPPYYtLcPdi8lSRqamge7A9qwvPoqtLUVAeyxx+Dxx9f9fOKJokxXnnsOJkyApibYbjsYPx7e9ra1n7XfN930Dd0tSZKGhIYEt4iYDnwHaAIuzMyz6tZHuf6DwHLghMy8s6e6ETEauBKYADwK/I/MfL5cdxrwCaAD+Gxm3tCI/VDvXnhhbQirDWSd3596CjLXrTN2bBG29twTjjhi3RC2++7rlr3ggnXb/OMf4corXzsKt+WWPQe7MWOKUTxJkjYkkfW/Zde3gYgm4G/AwUAbcAdwTGbeV1Pmg8BnKILb3sB3MnPvnupGxDeA5zLzrIg4FRiVmV+OiF2AWcBewLbAb4EdM7Ojp362trbm3LlzB7SvPZozB265BaZNg333ff220x997Nvq1bBoUdcjZZ3fX3xx3TobbVSEpe5C1LhxRZnufGj0HHZ7/hZuYRqPbLMvTz312jIdHbBwYfd9euwxeOmldeuMGPHaPtX2bbvtYPjwxhy3QWHf+se+rZeOjmKEfNXv59D0h1uIA6bR8t59aWkZQv8xGoLHbQ371j/2DYCImJeZrfXLGzHithewIDMfLjd0BTADuK+mzAzgx1mkxNsiYouIGEsxmtZd3RnAtLL+JcAtwJfL5Vdk5qvAIxGxoOzDnAbsS//MmVP8Ia5aBc3N8KlPFef8hoJHH4XzzoP2drK5meeP/hTPbDKB55/nNdMLL0DH6nWrb7ExTBwFo0bBqN3Kz1EwajSM2gI2GwnD6v8Bf76c5vfet1+9dB5Ee3HcjvgE/L/bFb8tOqf2dpo6Oti+nN5Tu+6tHTCmg5zSwapXOnh5WQevLOtgxcvl9GIHK//cwcpbO+hY2UETHTTTztN0sIQORrSUU3MHw5s7GN7UwfBhHTQP66B51XKGPfvs2r5uvTVssklxHrdzam5ed74RU1/abGuDCy8shiGH8N83+7Yeuulb5pofA1atKj/bYdXKtd/bV6397Cy3alVdna7W1dVd1UU7HavhbTzK/+I8mmin42vNXMBM2tieluZkePNqhrcUny3NSUtT+dm8mpamXGdZc1OxrLlpNc1NxfLmpqR5WM3nsOKzqSlpjprPYUlTzWeQxf80n3kGbr21OEhNTcW/w2PGwLBhRbLs/Kz9/kZ9Pv54cQqhQn/fhoSq9G3ECLjppkEJlo0Ycft7YHpm/s9y/mPA3pl5ck2ZXwJnZeZ/lfM3UYSwCd3VjYgXMnOLmjaez8xREfE94LbM/Em5/IfArzPz6p76+bqOuH3966z+yle806PRGhiMVkcTKzqaeWVlE6+sbGL5iiZefrWJl19pYtkrTby0vIlV2UQR75qYzD3syZ0MI1lNcBfv4omRkxlGB03ZseazifZ15od1tlC/rGbdsFz3c9167V2WGcbAfk6lN1IRrYLVDHtdPpNhMCzYIp9nq3yGABJ4hq14uWVUWWI1kUWtNfNkN8t6nh/Gasi1802s7u0QaAO3iia+sdn/w+nLTnvdtvF6jrh1NWBe/1umuzJ9qduf7RUFI2YCMwHGjx/fS7MDMG0aK9iYFlayiuEcxnW87SN7vX7bWw9vX3I7p9wyY52+nfnLvdh+e9h2W2hpGcTO3X47zJgBK1cW5y2vvx7e854ibA1rbAweBmxSTl3pvNu189TrA7+fw+TvH7jmuJ3M95h46CAO2WcyLIsgN+nZP/GPv/tQZf6+2bfeddW3fT+zFxttVPzHvnPqnO9t+UYjYOMRxY/VgH+Ubr+d5e9f27cP8Utufnmf7keaItb8J7api+YyiwGLFStg5Yris3N65ZV153tbN/bROZx87dqf0xnMZuLfv0E/p1lEyM5AV//59mdv4ws3f7gyf9/sW+/q+/bLl6Zx+iD0oxEjbvsCZ2bmB8r50wAy8+s1ZX4A3JKZs8r5ByhOg07orm5nmcxcVJ5WvSUzd6pvPyJuKNvo8VTp632N274xh2kU12rdxr6vuUB/MA3lvg3laxmG8nGzb/1j3/qnL9eiDpahfNzsW//Yt0J3I26NCG7NFDcYHAg8SXGDwf+VmffWlPkQcDJrb044JzP36qluRHwTWFJzc8LozPyniJgMXM7amxNuAiYN9s0Jb30rLF5cfN9mG4bUP2xDuW9D2VA+bvatf+zbhmcoHzf71j/2rfC6nSrNzPaIOBm4gWJk/KIyeJ1Urj8fuJ4itC2geBzIiT3VLZs+C7gqIj4BPA4cWda5NyKuoriBoR34dG+h7Y0wlP5i1RvKfRvKhvJxs2/9Y982PEP5uNm3/rFvPRvwiFtVvO6PA5EkSWqQ7kbcvBFSkiSpIgxukiRJFWFwkyRJqgiDmyRJUkUY3CRJkirC4CZJklQRBjdJkqSKMLhJkiRVhMFNkiSpIgxukiRJFWFwkyRJqgiDmyRJUkUY3CRJkirC4CZJklQRBjdJkqSKMLhJkiRVhMFNkiSpIgxukiRJFWFwkyRJqgiDmyRJUkUY3CRJkirC4CZJklQRBjdJkqSKMLhJkiRVhMFNkiSpIgYU3CJidETcGBEPlp+juik3PSIeiIgFEXFqb/Uj4uCImBcRfyk/31dT55ayrfnltPVA9kGSJKkqBjridipwU2ZOAm4q59cREU3AucAhwC7AMRGxSy/1nwU+nJm7AscDl9Y1e2xmTimnpwe4D5IkSZUw0OA2A7ik/H4JcHgXZfYCFmTmw5m5EriirNdt/cy8KzMXlsvvBUZExEYD7KskSVKlDTS4bZOZiwDKz65OW24HPFEz31Yu62v9jwB3ZearNct+VJ4m/eeIiAHugyRJUiU091YgIn4LvLWLVaf3cRtdBavsU8WIycC/Au+vWXxsZj4ZESOBnwEfA37cTf2ZwEyA8ePH97G7kiRJQ1OvwS0zD+puXUQsjoixmbkoIsYCXV1v1gZsXzM/Dug8Ddpt/YgYB1wDHJeZD9X058nyc1lEXE5xKrbL4JaZFwAXALS2tvYpLEqSJA1VAz1VOpvi5gHKz+u6KHMHMCkiJkbEcODosl639SNiC+BXwGmZ+cfOhiKiOSK2Kr+3AIcC9wxwHyRJkiphoMHtLODgiHgQOLicJyK2jYjrATKzHTgZuAG4H7gqM+/tqX5Z/r8B/1z32I+NgBsi4m5gPvAk8B8D3AdJkqRKiMw3xxnE1tbWnDt37mB3Q5IkqVcRMS8zW+uX++YESZKkijC4SZIkVYTBTZIkqSIMbpIkSRVhcJMkSaoIg5skSVJFGNwkSZIqwuAmSZJUEQY3SZKkijC4SZIkVYTBTZIkqSIMbpIkSRVhcJMkSaoIg5skSVJFGNwkSZIqwuAmSZJUEQY3SZKkijC4SZIkVYTBTZIkqSIMbpIkSRVhcJMkSaoIg5skSVJFGNwkSZIqwuAmSZJUEQY3SZKkihhQcIuI0RFxY0Q8WH6O6qbc9Ih4ICIWRMSpvdWPiAkR8UpEzC+n82vq7BkRfynbOiciYiD7IEmSVBUDHXE7FbgpMycBN5Xz64iIJuBc4BBgF+CYiNilD/Ufyswp5XRSzfLzgJnApHKaPsB9kCRJqoSBBrcZwCXl90uAw7sosxewIDMfzsyVwBVlvb7WXyMixgJvycw5mZnAj3urI0mStKEYaHDbJjMXAZSfW3dRZjvgiZr5tnJZb/UnRsRdEXFrROxf01ZbN21JkiRt0Jp7KxARvwXe2sWq0/u4ja6uQcte6iwCxmfmkojYE7g2Iiavb1sRMZPitCrjx4/vY3clSZKGpl6DW2Ye1N26iFgcEWMzc1F5GvPpLoq1AdvXzI8DFpbfu6yfma8Cr5bf50XEQ8COZVvjummrq75fAFwA0Nra2ltYlCRJGtIGeqp0NnB8+f144LouytwBTIqIiRExHDi6rNdt/YgYU97UQETsQHETwsPl6dRlEbFPeTfpcd1sU5IkaYMz0OB2FnBwRDwIHFzOExHbRsT1AJnZDpwM3ADcD1yVmff2VB94L3B3RPwf4GrgpMx8rlz3KeBCYAHwEPDrAe6DJElSJURxc+aGr7W1NefOnTvY3ZAkSepVRMzLzNb65b45QZIkqSIMbpIkSRVhcJMkSaoIg5skSVJFGNwkSZIqwuAmSZJUEQY3SZKkijC4SZIkVYTBTZIkqSIMbpIkSRVhcJMkSaoIg5skSVJFGNwkSZIqwuAmSZJUEQY3SZKkijC4SZIkVYTBTZIkqSIMbpIkSRVhcJMkSaoIg5skSVJFGNwkSZIqwuAmSZJUEQY3SZKkijC4SZIkVYTBTZIkqSIGFNwiYnRE3BgRD5afo7opNz0iHoiIBRFxam/1I+LYiJhfM62OiCnlulvKtjrXbT2QfZAkSaqKgY64nQrclJmTgJvK+XVERBNwLnAIsAtwTETs0lP9zLwsM6dk5hTgY8CjmTm/ptljO9dn5tMD3AdJkqRKGGhwmwFcUn6/BDi8izJ7AQsy8+HMXAlcUdbra/1jgFkD7KckSVLlDTS4bZOZiwDKz65OW24HPFEz31Yu62v9o3htcPtReZr0nyMiBrIDkiRJVdHcW4GI+C3w1i5Wnd7HbXQVrLJPFSP2BpZn5j01i4/NzCcjYiTwM4pTqT/upv5MYCbA+PHj+9hdSZKkoanX4JaZB3W3LiIWR8TYzFwUEWOBrq43awO2r5kfBywsv/dW/2jqRtsy88nyc1lEXE5xKrbL4JaZFwAXALS2tvYpLEqSJA1VAz1VOhs4vvx+PHBdF2XuACZFxMSIGE4Rxmb3Vj8ihgFHUlwT17msOSK2Kr+3AIcCtaNxkiRJG6yBBrezgIMj4kHg4HKeiNg2Iq4HyMx24GTgBuB+4KrMvLen+qX3Am2Z+XDNso2AGyLibmA+8CTwHwPcB0mSpEqIzDfHGcTW1tacO3fuYHdDkiSpVxExLzNb65f75gRJkqSKMLhJkiRVhMFNkiSpIgxukiRJFWFwkyRJqgiDmyRJUkUY3CRJkirC4CZJklQRBjdJkqSKMLhJkiRVhMFNkiSpIgxukiRJFWFwkyRJqgiDmyRJUkUY3CRJkirC4CZJklQRBjdJkqSKMLhJkiRVhMFNkiSpIgxukiRJFWFwkyRJqgiDmyRJUkUY3CRJkirC4CZJklQRBjdJkqSKGFBwi4jREXFjRDxYfo7qptz0iHggIhZExKk1y4+MiHsjYnVEtNbVOa0s/0BEfKBm+Z4R8Zdy3TkREQPZB0mSpKoY6IjbqcBNmTkJuKmcX0dENAHnAocAuwDHRMQu5ep7gL8Dfl9XZxfgaGAyMB34ftkOwHnATGBSOU0f4D5IkiRVwkCD2wzgkvL7JcDhXZTZC1iQmQ9n5krgirIemXl/Zj7QTbtXZOarmfkIsADYKyLGAm/JzDmZmcCPu9mmJEnSBmegwW2bzFwEUH5u3UWZ7YAnaubbymU96a7OduX39WlLkiRpg9DcW4GI+C3w1i5Wnd7HbXR1DVr2s856tRURMylOqwK8FBFdje410lbAs6/zNjZEHrf+8bj1j8etfzxu/eNx6x+PG7ytq4W9BrfMPKi7dRGxOCLGZuai8jTm010UawO2r5kfByzsZbPd1Wkrv/eprcy8ALigl201TETMzczW3kuqlsetfzxu/eNx6x+PW/943PrH49a9gZ4qnQ0cX34/HriuizJ3AJMiYmJEDKe46WB2H9o9OiI2ioiJFDch3F6ejl0WEfuUd5Me1802JUmSNjgDDW5nAQdHxIPAweU8EbFtRFwPkJntwMnADcD9wFWZeW9Z7oiIaAP2BX4VETeUde4FrgLuA34DfDozO8ptfgq4kOKGhYeAXw9wHyRJkiohipsz1QgRMbM8Pav14HHrH49b/3jc+sfj1j8et/7xuHXP4CZJklQRvvJKkiSpIgxuDdLda73UvYjYPiJujoj7y1effW6w+1QVEdEUEXdFxC8Huy9VEhFbRMTVEfHX8u/dvoPdpyqIiM+XP6P3RMSsiBgx2H0aiiLiooh4OiLuqVnWp1dDvpl1c9y+Wf6c3h0R10TEFoPYxSHF4NYAvbzWS91rB/4xM3cG9gE+7XHrs89R3Oyj9fMd4DeZ+Q5gdzyGvYqI7YDPAq2Z+U6gieLpAHqti3ntaxh7fTWkujxuNwLvzMzdgL8Bp73RnRqqDG6N0e1rvdS9zFyUmXeW35dR/BL1TRi9iIhxwIco7q5WH0XEW4D3Aj8EyMyVmfnCoHaqOpqBjSOiGdiE3p/F+aaUmb8Hnqtb3JdXQ76pdXXcMvM/y6dSANzGus9wfVMzuDVGf17rpRoRMQF4F/DnQe5KFZwN/BOwepD7UTU7AM8APypPM18YEZsOdqeGusx8Evg34HFgEbA0M/9zcHtVKX15NaR69nF89NcaBrfG6M9rvVSKiM2AnwGnZOaLg92foSwiDgWezsx5g92XCmoG9gDOy8x3AS/jaatelddkzQAmAtsCm0bERwe3V3qziIjTKS6ruWyw+zJUGNwaoz+v9RIQES0Uoe2yzPz5YPenAt4DHBYRj1Kckn9fRPxkcLtUGW1AW2Z2jupeTRHk1LODgEcy85nMXAX8HHj3IPepShaXr4Skh1dDqgsRcTxwKHBs+uyyNQxujdGf13q96ZWvLfshcH9mfnuw+1MFmXlaZo7LzAkUf89+l5mOfvRBZj4FPBERO5WLDqR4O4t69jiwT0RsUv7MHog3dayPvrwaUnUiYjrwZeCwzFw+2P0ZSgxuDdDTa73Uo/cAH6MYNZpfTh8c7E5pg/YZ4LKIuBuYAnxtcLsz9JUjlFcDdwJ/ofi94RPtuxARs4A5wE4R0RYRn6CbV0NqrW6O2/eAkcCN5e+G8we1k0OIb06QJEmqCEfcJEmSKsLgJkmSVBEGN0mSpIowuEmSJFWEwU2SJKkimge7A5I0lEREB8VjL1oonth+CXB2ZvqKMUmDzuAmSet6JTOnAETE1sDlwObA/x7MTkkSeKpUkrqVmU8DM4GTozAhIv4QEXeW07sBIuLSiJjRWS8iLouIwyJickTcXj5A9O6ImDRY+yJpw+ADeCWpRkS8lJmb1S17HngHsAxYnZkryhA2KzNbI2Iq8PnMPDwiNgfmA5OAfwduy8zLytfhNWXmK2/oDknaoHiqVJJ6F+VnC/C9iJgCdAA7AmTmrRFxbnlq9e+An2Vme0TMAU6PiHHAzzPzwUHou6QNiKdKJakHEbEDRUh7Gvg8sBjYHWgFhtcUvRQ4FjgR+BFAZl4OHAa8AtwQEe9743ouaUNkcJOkbkTEGOB84HtZXFeyObCovMP0Y0BTTfGLgVMAMvPesv4OwMOZeQ4wG9jtDeu8pA2Sp0olaV0bR8R81j4O5FLg2+W67wM/i4gjgZuBlzsrZebiiLgfuLamraOAj0bEKuAp4Kuve+8lbdC8OUGSGiAiNqF4/tsembl0sPsjacPkqVJJGqCIOAj4K/BdQ5uk15MjbpIkSRXhiJskSVJFGNwkSZIqwuAmSZJUEQY3SZKkijC4SZIkVYTBTZIkqSL+f0Cdc4oEwGHDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_Y = testY[0][len(testY[0])-15:len(testY[0])-1]\n",
    "test_Ypred = testPredict[len(testPredict)-15:len(testPredict)-1]\n",
    "plt.subplots(figsize=(10, 5))\n",
    "plt.title(product_name.upper() + \" - Forecast vs Actual\", fontsize=14)\n",
    "plt.plot(pd.Series(numpy.ravel(test_Y)), \"bs-\", markersize=3, label=\"Actual\")\n",
    "plt.plot(pd.Series(numpy.ravel(test_Ypred)), \"ro-\", markersize=3, label=\"Forecast\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylim([-0.01,0.01])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00015380 RMSE\n",
      "Test Score: 0.00011402 RMSE\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.8f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.8f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot baseline and predictions\n",
    "# plt.plot(scaler.inverse_transform(dataset),\"b-\", label=\"Actual\")\n",
    "# plt.plot(trainPredictPlot,\"y-\", label=\"Train pred\")\n",
    "# plt.plot(scaler.inverse_transform(testY)[0],\"b-\", label=\"Actual\")\n",
    "# plt.plot(testPredictPlot, \"g-\", label=\"Test pred\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.ylim([-0.02,0.02])\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18f9e42b91da9395310def41b953de3eaf324ff700d0d0be600380b7bf53ba90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
